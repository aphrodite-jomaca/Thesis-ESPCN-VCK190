graph_name: "Net"
op_node {
  op_name: "Net__conv1_weight_new"
  op_type: "const-fix"
  op_attr {
    key: "data"
    value {
      bytes_value {
      }
    }
  }
  op_attr {
    key: "data_type"
    value {
      string_value: "XINT8"
    }
  }
  op_attr {
    key: "device"
    value {
      string_value: "DPU"
    }
  }
  op_attr {
    key: "shape"
    value {
      int32_vec_value {
        value: 64
        value: 5
        value: 5
        value: 1
      }
    }
  }
  output_tensor {
    tensor_name: "Net__conv1_weight_fix"
    tensor_dim: 64
    tensor_dim: 5
    tensor_dim: 5
    tensor_dim: 1
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "ddr_addr"
      value {
        int32_value: 0
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 7
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "location"
      value {
        int32_value: 1
      }
    }
    tensor_attr {
      key: "reg_id"
      value {
        int32_value: 0
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
    tensor_attr {
      key: "stride"
      value {
        int32_vec_value {
          value: 80
          value: 16
          value: 16
          value: 1
        }
      }
    }
  }
}
op_node {
  op_name: "Net__conv1_bias_new"
  op_type: "const-fix"
  op_attr {
    key: "data"
    value {
      bytes_value {
      }
    }
  }
  op_attr {
    key: "data_type"
    value {
      string_value: "XINT8"
    }
  }
  op_attr {
    key: "device"
    value {
      string_value: "DPU"
    }
  }
  op_attr {
    key: "shape"
    value {
      int32_vec_value {
        value: 64
      }
    }
  }
  output_tensor {
    tensor_name: "Net__conv1_bias_fix"
    tensor_dim: 64
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "ddr_addr"
      value {
        int32_value: 5120
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "location"
      value {
        int32_value: 1
      }
    }
    tensor_attr {
      key: "reg_id"
      value {
        int32_value: 0
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
  }
}
op_node {
  op_name: "Net__conv3_weight_new"
  op_type: "const-fix"
  op_attr {
    key: "data"
    value {
      bytes_value {
      }
    }
  }
  op_attr {
    key: "data_type"
    value {
      string_value: "XINT8"
    }
  }
  op_attr {
    key: "device"
    value {
      string_value: "DPU"
    }
  }
  op_attr {
    key: "shape"
    value {
      int32_vec_value {
        value: 32
        value: 3
        value: 3
        value: 64
      }
    }
  }
  output_tensor {
    tensor_name: "Net__conv3_weight_fix"
    tensor_dim: 32
    tensor_dim: 3
    tensor_dim: 3
    tensor_dim: 64
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "ddr_addr"
      value {
        int32_value: 0
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "location"
      value {
        int32_value: 1
      }
    }
    tensor_attr {
      key: "reg_id"
      value {
        int32_value: 0
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
    tensor_attr {
      key: "stride"
      value {
        int32_vec_value {
          value: 576
          value: 192
          value: 64
          value: 1
        }
      }
    }
  }
}
op_node {
  op_name: "Net__conv3_bias_new"
  op_type: "const-fix"
  op_attr {
    key: "data"
    value {
      bytes_value {
      }
    }
  }
  op_attr {
    key: "data_type"
    value {
      string_value: "XINT8"
    }
  }
  op_attr {
    key: "device"
    value {
      string_value: "DPU"
    }
  }
  op_attr {
    key: "shape"
    value {
      int32_vec_value {
        value: 32
      }
    }
  }
  output_tensor {
    tensor_name: "Net__conv3_bias_fix"
    tensor_dim: 32
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "ddr_addr"
      value {
        int32_value: 18432
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 9
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "location"
      value {
        int32_value: 1
      }
    }
    tensor_attr {
      key: "reg_id"
      value {
        int32_value: 0
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
  }
}
op_node {
  op_name: "Net__conv4_weight_new"
  op_type: "const-fix"
  op_attr {
    key: "data"
    value {
      bytes_value {
      }
    }
  }
  op_attr {
    key: "data_type"
    value {
      string_value: "XINT8"
    }
  }
  op_attr {
    key: "device"
    value {
      string_value: "DPU"
    }
  }
  op_attr {
    key: "shape"
    value {
      int32_vec_value {
        value: 4
        value: 3
        value: 3
        value: 32
      }
    }
  }
  output_tensor {
    tensor_name: "Net__conv4_weight_fix"
    tensor_dim: 4
    tensor_dim: 3
    tensor_dim: 3
    tensor_dim: 32
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "ddr_addr"
      value {
        int32_value: 0
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 9
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "location"
      value {
        int32_value: 1
      }
    }
    tensor_attr {
      key: "reg_id"
      value {
        int32_value: 0
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
    tensor_attr {
      key: "stride"
      value {
        int32_vec_value {
          value: 288
          value: 96
          value: 32
          value: 1
        }
      }
    }
  }
}
op_node {
  op_name: "Net__conv4_bias_new"
  op_type: "const-fix"
  op_attr {
    key: "data"
    value {
      bytes_value {
      }
    }
  }
  op_attr {
    key: "data_type"
    value {
      string_value: "XINT8"
    }
  }
  op_attr {
    key: "device"
    value {
      string_value: "DPU"
    }
  }
  op_attr {
    key: "shape"
    value {
      int32_vec_value {
        value: 4
      }
    }
  }
  output_tensor {
    tensor_name: "Net__conv4_bias_fix"
    tensor_dim: 4
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "ddr_addr"
      value {
        int32_value: 4608
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 10
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "location"
      value {
        int32_value: 1
      }
    }
    tensor_attr {
      key: "reg_id"
      value {
        int32_value: 0
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
  }
}
op_node {
  op_name: "Net__input_0"
  op_type: "data-fix"
  op_attr {
    key: "data_type"
    value {
      string_value: "XINT8"
    }
  }
  op_attr {
    key: "device"
    value {
      string_value: "USER"
    }
  }
  op_attr {
    key: "shape"
    value {
      int32_vec_value {
        value: 1
        value: 16
        value: 16
        value: 1
      }
    }
  }
  output_tensor {
    tensor_name: "Net__input_0_fix"
    tensor_dim: 1
    tensor_dim: 16
    tensor_dim: 16
    tensor_dim: 1
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 7
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
  }
}
op_node {
  op_name: "Net__input_0_upload_0"
  op_type: "upload"
  op_attr {
    key: "device"
    value {
      string_value: "DPU"
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__input_0"
  }
  output_tensor {
    tensor_name: "Net__input_0_fix_upload_0"
    tensor_dim: 1
    tensor_dim: 16
    tensor_dim: 16
    tensor_dim: 1
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "ddr_addr"
      value {
        int32_value: 64
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 7
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "location"
      value {
        int32_value: 1
      }
    }
    tensor_attr {
      key: "reg_id"
      value {
        int32_value: 2
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
    tensor_attr {
      key: "stride"
      value {
        int32_vec_value {
          value: 256
          value: 16
          value: 1
          value: 1
        }
      }
    }
  }
}
op_node {
  op_name: "Net__Net_Conv2d_conv1__168"
  op_type: "conv2d-fix"
  op_attr {
    key: "bias_term"
    value {
      bool_value: true
    }
  }
  op_attr {
    key: "channel_augmentation"
    value {
      int32_value: 1
    }
  }
  op_attr {
    key: "device"
    value {
      string_value: "DPU"
    }
  }
  op_attr {
    key: "dilation"
    value {
      int32_vec_value {
        value: 1
        value: 1
      }
    }
  }
  op_attr {
    key: "group"
    value {
      int32_value: 1
    }
  }
  op_attr {
    key: "hsigmoid_in"
    value {
      int32_value: -128
    }
  }
  op_attr {
    key: "in_dim"
    value {
      int32_value: 1
    }
  }
  op_attr {
    key: "kernel"
    value {
      int32_vec_value {
        value: 5
        value: 5
      }
    }
  }
  op_attr {
    key: "nonlinear"
    value {
      string_value: "NONE"
    }
  }
  op_attr {
    key: "out_dim"
    value {
      int32_value: 64
    }
  }
  op_attr {
    key: "pad"
    value {
      int32_vec_value {
        value: 2
        value: 2
        value: 2
        value: 2
      }
    }
  }
  op_attr {
    key: "pad_mode"
    value {
      string_value: "FLOOR"
    }
  }
  op_attr {
    key: "shift_hsigmoid"
    value {
      int32_value: -128
    }
  }
  op_attr {
    key: "shift_hswish"
    value {
      int32_value: -128
    }
  }
  op_attr {
    key: "stride"
    value {
      int32_vec_value {
        value: 1
        value: 1
      }
    }
  }
  op_attr {
    key: "workload"
    value {
      uint64_value: 835584
    }
  }
  op_attr {
    key: "workload_on_arch"
    value {
      uint64_value: 2637824
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__input_0_upload_0"
  }
  args {
    arg_name: "weights"
    arg_ops: "Net__conv1_weight_new"
  }
  args {
    arg_name: "bias"
    arg_ops: "Net__conv1_bias_new"
  }
  output_tensor {
    tensor_name: "Net__Net_Conv2d_conv1__168_fix_download_0"
    tensor_dim: 1
    tensor_dim: 16
    tensor_dim: 16
    tensor_dim: 64
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "ddr_addr"
      value {
        int32_value: 0
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 6
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "location"
      value {
        int32_value: 1
      }
    }
    tensor_attr {
      key: "reg_id"
      value {
        int32_value: 3
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
    tensor_attr {
      key: "stride"
      value {
        int32_vec_value {
          value: 16384
          value: 1024
          value: 64
          value: 1
        }
      }
    }
  }
}
op_node {
  op_name: "Net__Net_Conv2d_conv1__168_download_0"
  op_type: "download"
  op_attr {
    key: "device"
    value {
      string_value: "DPU"
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__Net_Conv2d_conv1__168"
  }
  output_tensor {
    tensor_name: "Net__Net_Conv2d_conv1__168_fix"
    tensor_dim: 1
    tensor_dim: 16
    tensor_dim: 16
    tensor_dim: 64
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 6
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
  }
}
op_node {
  op_name: "Net__Net_Conv2d_conv1__168_fix_Net__Net_Tanh_tanh__input_3"
  op_type: "fix2float"
  op_attr {
    key: "bit_width"
    value {
      int32_value: 8
    }
  }
  op_attr {
    key: "device"
    value {
      string_value: "CPU"
    }
  }
  op_attr {
    key: "fix_point"
    value {
      int32_value: 6
    }
  }
  op_attr {
    key: "if_signed"
    value {
      bool_value: true
    }
  }
  op_attr {
    key: "round_mode"
    value {
      string_value: "DPU_ROUND"
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__Net_Conv2d_conv1__168_download_0"
  }
  output_tensor {
    tensor_name: "Net__Net_Conv2d_conv1__168_fix_Net__Net_Tanh_tanh__input_3"
    tensor_dim: 1
    tensor_dim: 16
    tensor_dim: 16
    tensor_dim: 64
    data_type: 4
    tensor_bit_width: 32
  }
}
op_node {
  op_name: "Net__Net_Tanh_tanh__input_3"
  op_type: "tanh"
  op_attr {
    key: "device"
    value {
      string_value: "CPU"
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__Net_Conv2d_conv1__168_fix_Net__Net_Tanh_tanh__input_3"
  }
  output_tensor {
    tensor_name: "Net__Net_Tanh_tanh__input_3"
    tensor_dim: 1
    tensor_dim: 16
    tensor_dim: 16
    tensor_dim: 64
    data_type: 4
    tensor_bit_width: 32
  }
}
op_node {
  op_name: "Net__Net_Tanh_tanh__input_3_fix"
  op_type: "float2fix"
  op_attr {
    key: "bit_width"
    value {
      int32_value: 8
    }
  }
  op_attr {
    key: "device"
    value {
      string_value: "CPU"
    }
  }
  op_attr {
    key: "fix_point"
    value {
      int32_value: 7
    }
  }
  op_attr {
    key: "if_signed"
    value {
      bool_value: true
    }
  }
  op_attr {
    key: "round_mode"
    value {
      string_value: "DPU_ROUND"
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__Net_Tanh_tanh__input_3"
  }
  output_tensor {
    tensor_name: "Net__Net_Tanh_tanh__input_3_fix"
    tensor_dim: 1
    tensor_dim: 16
    tensor_dim: 16
    tensor_dim: 64
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 7
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
  }
}
op_node {
  op_name: "Net__Net_Tanh_tanh__input_3_fix_upload_0"
  op_type: "upload"
  op_attr {
    key: "device"
    value {
      string_value: "DPU"
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__Net_Tanh_tanh__input_3_fix"
  }
  output_tensor {
    tensor_name: "Net__Net_Tanh_tanh__input_3_fix_upload_0"
    tensor_dim: 1
    tensor_dim: 16
    tensor_dim: 16
    tensor_dim: 64
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "ddr_addr"
      value {
        int32_value: 0
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 7
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "location"
      value {
        int32_value: 1
      }
    }
    tensor_attr {
      key: "reg_id"
      value {
        int32_value: 2
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
    tensor_attr {
      key: "stride"
      value {
        int32_vec_value {
          value: 16384
          value: 1024
          value: 64
          value: 1
        }
      }
    }
  }
}
op_node {
  op_name: "Net__Net_Conv2d_conv3__188"
  op_type: "conv2d-fix"
  op_attr {
    key: "bias_term"
    value {
      bool_value: true
    }
  }
  op_attr {
    key: "device"
    value {
      string_value: "DPU"
    }
  }
  op_attr {
    key: "dilation"
    value {
      int32_vec_value {
        value: 1
        value: 1
      }
    }
  }
  op_attr {
    key: "group"
    value {
      int32_value: 1
    }
  }
  op_attr {
    key: "hsigmoid_in"
    value {
      int32_value: -128
    }
  }
  op_attr {
    key: "in_dim"
    value {
      int32_value: 64
    }
  }
  op_attr {
    key: "kernel"
    value {
      int32_vec_value {
        value: 3
        value: 3
      }
    }
  }
  op_attr {
    key: "nonlinear"
    value {
      string_value: "NONE"
    }
  }
  op_attr {
    key: "out_dim"
    value {
      int32_value: 32
    }
  }
  op_attr {
    key: "pad"
    value {
      int32_vec_value {
        value: 1
        value: 1
        value: 1
        value: 1
      }
    }
  }
  op_attr {
    key: "pad_mode"
    value {
      string_value: "FLOOR"
    }
  }
  op_attr {
    key: "shift_hsigmoid"
    value {
      int32_value: -128
    }
  }
  op_attr {
    key: "shift_hswish"
    value {
      int32_value: -128
    }
  }
  op_attr {
    key: "stride"
    value {
      int32_vec_value {
        value: 1
        value: 1
      }
    }
  }
  op_attr {
    key: "workload"
    value {
      uint64_value: 9445376
    }
  }
  op_attr {
    key: "workload_on_arch"
    value {
      uint64_value: 9445376
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__Net_Tanh_tanh__input_3_fix_upload_0"
  }
  args {
    arg_name: "weights"
    arg_ops: "Net__conv3_weight_new"
  }
  args {
    arg_name: "bias"
    arg_ops: "Net__conv3_bias_new"
  }
  output_tensor {
    tensor_name: "Net__Net_Conv2d_conv3__188_fix_download_0"
    tensor_dim: 1
    tensor_dim: 16
    tensor_dim: 16
    tensor_dim: 32
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "ddr_addr"
      value {
        int32_value: 0
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 5
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "location"
      value {
        int32_value: 1
      }
    }
    tensor_attr {
      key: "reg_id"
      value {
        int32_value: 3
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
    tensor_attr {
      key: "stride"
      value {
        int32_vec_value {
          value: 8192
          value: 512
          value: 32
          value: 1
        }
      }
    }
  }
}
op_node {
  op_name: "Net__Net_Conv2d_conv3__188_download_0"
  op_type: "download"
  op_attr {
    key: "device"
    value {
      string_value: "DPU"
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__Net_Conv2d_conv3__188"
  }
  output_tensor {
    tensor_name: "Net__Net_Conv2d_conv3__188_fix"
    tensor_dim: 1
    tensor_dim: 16
    tensor_dim: 16
    tensor_dim: 32
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 5
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
  }
}
op_node {
  op_name: "Net__Net_Conv2d_conv3__188_fix_Net__Net_Tanh_tanh__input"
  op_type: "fix2float"
  op_attr {
    key: "bit_width"
    value {
      int32_value: 8
    }
  }
  op_attr {
    key: "device"
    value {
      string_value: "CPU"
    }
  }
  op_attr {
    key: "fix_point"
    value {
      int32_value: 5
    }
  }
  op_attr {
    key: "if_signed"
    value {
      bool_value: true
    }
  }
  op_attr {
    key: "round_mode"
    value {
      string_value: "DPU_ROUND"
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__Net_Conv2d_conv3__188_download_0"
  }
  output_tensor {
    tensor_name: "Net__Net_Conv2d_conv3__188_fix_Net__Net_Tanh_tanh__input"
    tensor_dim: 1
    tensor_dim: 16
    tensor_dim: 16
    tensor_dim: 32
    data_type: 4
    tensor_bit_width: 32
  }
}
op_node {
  op_name: "Net__Net_Tanh_tanh__input"
  op_type: "tanh"
  op_attr {
    key: "device"
    value {
      string_value: "CPU"
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__Net_Conv2d_conv3__188_fix_Net__Net_Tanh_tanh__input"
  }
  output_tensor {
    tensor_name: "Net__Net_Tanh_tanh__input"
    tensor_dim: 1
    tensor_dim: 16
    tensor_dim: 16
    tensor_dim: 32
    data_type: 4
    tensor_bit_width: 32
  }
}
op_node {
  op_name: "Net__Net_Tanh_tanh__input_fix"
  op_type: "float2fix"
  op_attr {
    key: "bit_width"
    value {
      int32_value: 8
    }
  }
  op_attr {
    key: "device"
    value {
      string_value: "CPU"
    }
  }
  op_attr {
    key: "fix_point"
    value {
      int32_value: 7
    }
  }
  op_attr {
    key: "if_signed"
    value {
      bool_value: true
    }
  }
  op_attr {
    key: "round_mode"
    value {
      string_value: "DPU_ROUND"
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__Net_Tanh_tanh__input"
  }
  output_tensor {
    tensor_name: "Net__Net_Tanh_tanh__input_fix"
    tensor_dim: 1
    tensor_dim: 16
    tensor_dim: 16
    tensor_dim: 32
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 7
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
  }
}
op_node {
  op_name: "Net__Net_Tanh_tanh__input_fix_upload_0"
  op_type: "upload"
  op_attr {
    key: "device"
    value {
      string_value: "DPU"
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__Net_Tanh_tanh__input_fix"
  }
  output_tensor {
    tensor_name: "Net__Net_Tanh_tanh__input_fix_upload_0"
    tensor_dim: 1
    tensor_dim: 16
    tensor_dim: 16
    tensor_dim: 32
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "ddr_addr"
      value {
        int32_value: 0
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 7
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "location"
      value {
        int32_value: 1
      }
    }
    tensor_attr {
      key: "reg_id"
      value {
        int32_value: 2
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
    tensor_attr {
      key: "stride"
      value {
        int32_vec_value {
          value: 8192
          value: 512
          value: 32
          value: 1
        }
      }
    }
  }
}
op_node {
  op_name: "Net__Net_Conv2d_conv4__208"
  op_type: "conv2d-fix"
  op_attr {
    key: "bias_term"
    value {
      bool_value: true
    }
  }
  op_attr {
    key: "device"
    value {
      string_value: "DPU"
    }
  }
  op_attr {
    key: "dilation"
    value {
      int32_vec_value {
        value: 1
        value: 1
      }
    }
  }
  op_attr {
    key: "group"
    value {
      int32_value: 1
    }
  }
  op_attr {
    key: "hsigmoid_in"
    value {
      int32_value: -128
    }
  }
  op_attr {
    key: "in_dim"
    value {
      int32_value: 32
    }
  }
  op_attr {
    key: "kernel"
    value {
      int32_vec_value {
        value: 3
        value: 3
      }
    }
  }
  op_attr {
    key: "nonlinear"
    value {
      string_value: "NONE"
    }
  }
  op_attr {
    key: "out_dim"
    value {
      int32_value: 4
    }
  }
  op_attr {
    key: "pad"
    value {
      int32_vec_value {
        value: 1
        value: 1
        value: 1
        value: 1
      }
    }
  }
  op_attr {
    key: "pad_mode"
    value {
      string_value: "FLOOR"
    }
  }
  op_attr {
    key: "shift_hsigmoid"
    value {
      int32_value: -128
    }
  }
  op_attr {
    key: "shift_hswish"
    value {
      int32_value: -128
    }
  }
  op_attr {
    key: "stride"
    value {
      int32_vec_value {
        value: 1
        value: 1
      }
    }
  }
  op_attr {
    key: "workload"
    value {
      uint64_value: 590848
    }
  }
  op_attr {
    key: "workload_on_arch"
    value {
      uint64_value: 4726784
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__Net_Tanh_tanh__input_fix_upload_0"
  }
  args {
    arg_name: "weights"
    arg_ops: "Net__conv4_weight_new"
  }
  args {
    arg_name: "bias"
    arg_ops: "Net__conv4_bias_new"
  }
  output_tensor {
    tensor_name: "Net__Net_Conv2d_conv4__208_fix"
    tensor_dim: 1
    tensor_dim: 16
    tensor_dim: 16
    tensor_dim: 4
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "ddr_addr"
      value {
        int32_value: 0
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 7
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "location"
      value {
        int32_value: 0
      }
    }
    tensor_attr {
      key: "reg_id"
      value {
        int32_value: 1
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
  }
}
op_node {
  op_name: "Net__Net_PixelShuffle_pixel_shuffle__210_convert_to_tile"
  op_type: "tile-fix"
  op_attr {
    key: "device"
    value {
      string_value: "DPU"
    }
  }
  op_attr {
    key: "reverse"
    value {
      bool_value: true
    }
  }
  op_attr {
    key: "stride"
    value {
      int32_value: 2
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__Net_Conv2d_conv4__208"
  }
  output_tensor {
    tensor_name: "Net__Net_PixelShuffle_pixel_shuffle__210_fix_download_0"
    tensor_dim: 1
    tensor_dim: 32
    tensor_dim: 32
    tensor_dim: 1
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "ddr_addr"
      value {
        int32_value: 0
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 7
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "location"
      value {
        int32_value: 1
      }
    }
    tensor_attr {
      key: "reg_id"
      value {
        int32_value: 3
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
    tensor_attr {
      key: "stride"
      value {
        int32_vec_value {
          value: 1024
          value: 32
          value: 1
          value: 1
        }
      }
    }
  }
}
op_node {
  op_name: "Net__Net_PixelShuffle_pixel_shuffle__210_convert_to_tile_download_0"
  op_type: "download"
  op_attr {
    key: "device"
    value {
      string_value: "DPU"
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__Net_PixelShuffle_pixel_shuffle__210_convert_to_tile"
  }
  output_tensor {
    tensor_name: "Net__Net_PixelShuffle_pixel_shuffle__210_fix"
    tensor_dim: 1
    tensor_dim: 32
    tensor_dim: 32
    tensor_dim: 1
    data_type: 2
    tensor_bit_width: 8
    tensor_attr {
      key: "bit_width"
      value {
        int32_value: 8
      }
    }
    tensor_attr {
      key: "fix_point"
      value {
        int32_value: 7
      }
    }
    tensor_attr {
      key: "if_signed"
      value {
        bool_value: true
      }
    }
    tensor_attr {
      key: "round_mode"
      value {
        string_value: "DPU_ROUND"
      }
    }
  }
}
op_node {
  op_name: "Net__Net_PixelShuffle_pixel_shuffle__210_fix_"
  op_type: "fix2float"
  op_attr {
    key: "bit_width"
    value {
      int32_value: 8
    }
  }
  op_attr {
    key: "device"
    value {
      string_value: "CPU"
    }
  }
  op_attr {
    key: "fix_point"
    value {
      int32_value: 7
    }
  }
  op_attr {
    key: "if_signed"
    value {
      bool_value: true
    }
  }
  op_attr {
    key: "round_mode"
    value {
      string_value: "DPU_ROUND"
    }
  }
  args {
    arg_name: "input"
    arg_ops: "Net__Net_PixelShuffle_pixel_shuffle__210_convert_to_tile_download_0"
  }
  output_tensor {
    tensor_name: "Net__Net_PixelShuffle_pixel_shuffle__210_fix_"
    tensor_dim: 1
    tensor_dim: 32
    tensor_dim: 32
    tensor_dim: 1
    data_type: 4
    tensor_bit_width: 32
  }
}
subg_root {
  subgraph_name: "root"
  subg_attr {
    key: "workload"
    value {
      uint64_value: 10871808
    }
  }
  subg_attr {
    key: "workload_on_arch"
    value {
      uint64_value: 16809984
    }
  }
  subg_child {
    subgraph_name: "subgraph_Net__input_0"
    op_name: "Net__input_0"
    subg_attr {
      key: "device"
      value {
        string_value: "USER"
      }
    }
    subg_attr {
      key: "workload"
      value {
        uint64_value: 0
      }
    }
    subg_attr {
      key: "workload_on_arch"
      value {
        uint64_value: 0
      }
    }
  }
  subg_child {
    subgraph_name: "subgraph_Net__Net_Conv2d_conv1__168"
    subg_attr {
      key: "children_topological_sort"
      value {
        string_vec_value {
          value: "subgraph_Net__Net_Conv2d_conv1__168"
        }
      }
    }
    subg_attr {
      key: "debug_mode"
      value {
        string_value: "function"
      }
    }
    subg_attr {
      key: "device"
      value {
        string_value: "DPU"
      }
    }
    subg_attr {
      key: "dpu_fingerprint"
      value {
        uint64_value: 433190036771510369
      }
    }
    subg_attr {
      key: "dpu_name"
      value {
        string_value: "DPUCVDX8G_ISA3_C32B6"
      }
    }
    subg_attr {
      key: "if_prefetch"
      value {
        bool_value: true
      }
    }
    subg_attr {
      key: "mc_code"
      value {
        bytes_value {
          value: bytes = 820 md5sum = 2b2b08ca1f02cd65f09a5c6348a02890
          head: 
          0x5625b063a2c0 00000000: 0040 1801 01fc 0000 0000 0000 00fc 0000
          0x5625b063a2d0 00000010: 0000 0000 0014 0000 0000 0190 001c 4000
          0x5625b063a2e0 00000020: 3f00 4000 030c 0100 0000 6001 0400 0000
          0x5625b063a2f0 00000030: 0000 1401 003c 0000 3f10 0000 043c 0000
          0x5625b063a300 00000040: 0000 0000 0000 0000 0000 1001 0000 0000
          0x5625b063a310 00000050: 0000 0000 0f10 0008 0200 0013 3e00 0000
          0x5625b063a320 00000060: 0040 1001 0000 0000 0000 0000 0f10 0008
          0x5625b063a330 00000070: 0200 0013 4e00 0000 0080 1001 0000 0000
          0x5625b063a340 00000080: 0000 0000 0f10 0008 0200 0013 5e00 0000
          0x5625b063a350 00000090: 00c0 1001 0000 0000 0000 0000 0f10 0008
          tail: 
          0x5625b063a554 00000000: 03fc 0000 0ffc 0000 0300 0000 0020 0000
          0x5625b063a564 00000010: 4040 2242 03fc 0000 0ffc 0000 0300 0000
          0x5625b063a574 00000020: 0024 0000 4080 2242 03fc 0000 0ffc 0000
          0x5625b063a584 00000030: 0300 0000 0028 0000 40c0 2242 03fc 0000
          0x5625b063a594 00000040: 0ffc 0000 0300 0000 002c 0000 4000 2342
          0x5625b063a5a4 00000050: 03fc 0000 0ffc 0000 0300 0000 0030 0000
          0x5625b063a5b4 00000060: 4040 2342 03fc 0000 0ffc 0000 0300 0000
          0x5625b063a5c4 00000070: 0034 0000 4080 2342 03fc 0000 0ffc 0000
          0x5625b063a5d4 00000080: 0300 0000 0038 0000 40c0 2342 03fc 0000
          0x5625b063a5e4 00000090: 0ffc 0000 0300 0000 003c 0000 0000 2072
          
        }
      }
    }
    subg_attr {
      key: "mc_code_preload"
      value {
        bytes_value {
        }
      }
    }
    subg_attr {
      key: "reg_id_to_context_type"
      value {
        map_string_2_string_value {
          value {
            key: "REG_0"
            value: "CONST"
          }
          value {
            key: "REG_2"
            value: "DATA"
          }
          value {
            key: "REG_3"
            value: "DATA"
          }
        }
      }
    }
    subg_attr {
      key: "reg_id_to_context_type_v2"
      value {
        map_string_2_string_value {
          value {
            key: "REG_0"
            value: "CONST"
          }
          value {
            key: "REG_2"
            value: "INTERFACE"
          }
          value {
            key: "REG_3"
            value: "INTERFACE"
          }
        }
      }
    }
    subg_attr {
      key: "reg_id_to_hw_segment"
      value {
        map_string_2_string_value {
          value {
            key: "REG_0"
            value: "W0"
          }
          value {
            key: "REG_2"
            value: "D0"
          }
          value {
            key: "REG_3"
            value: "D0"
          }
        }
      }
    }
    subg_attr {
      key: "reg_id_to_parameter_value"
      value {
        map_string_2_bytes_value {
          value {
            key: "REG_0"
            value {
              value: bytes = 5184 md5sum = b9a0ae9726c0fc70d671f885e967f94b
              head: 
              0x5625b06a8990 00000000: dcfe ed34 f100 0000 0000 0000 0000 0000
              0x5625b06a89a0 00000010: fdfb f716 e800 0000 0000 0000 0000 0000
              0x5625b06a89b0 00000020: 1108 f8eb 0a00 0000 0000 0000 0000 0000
              0x5625b06a89c0 00000030: e8e3 1f04 0800 0000 0000 0000 0000 0000
              0x5625b06a89d0 00000040: 0c10 e823 ff00 0000 0000 0000 0000 0000
              0x5625b06a89e0 00000050: e8f7 df29 1100 0000 0000 0000 0000 0000
              0x5625b06a89f0 00000060: fbe7 f115 f800 0000 0000 0000 0000 0000
              0x5625b06a8a00 00000070: 0929 ed03 1d00 0000 0000 0000 0000 0000
              0x5625b06a8a10 00000080: f7ff 0a03 e900 0000 0000 0000 0000 0000
              0x5625b06a8a20 00000090: 0305 f919 d800 0000 0000 0000 0000 0000
              tail: 
              0x5625b06a9d30 00000000: e209 3d0f 0000 0000 0000 0000 0000 0000
              0x5625b06a9d40 00000010: 0df9 08e4 1100 0000 0000 0000 0000 0000
              0x5625b06a9d50 00000020: 03fe 0ae6 0500 0000 0000 0000 0000 0000
              0x5625b06a9d60 00000030: 07e8 e312 3100 0000 0000 0000 0000 0000
              0x5625b06a9d70 00000040: 0d08 0002 0900 0000 0000 0000 0000 0000
              0x5625b06a9d80 00000050: f5f6 d9f3 1200 0000 0000 0000 0000 0000
              0x5625b06a9d90 00000060: fd07 fc09 08c2 e907 ee06 0d0f 141d 1303
              0x5625b06a9da0 00000070: ed09 e3e7 22cc ecf7 e2f9 1822 f323 1bfc
              0x5625b06a9db0 00000080: fc19 192c d822 e7f4 fdbe d509 fd1f 0612
              0x5625b06a9dc0 00000090: fccc 04fd ffe5 d1fd d0ea fd02 09f0 2e03
              
            }
          }
        }
      }
    }
    subg_attr {
      key: "reg_id_to_size"
      value {
        map_string_2_int32_value {
          value {
            key: "REG_0"
            value: 5184
          }
          value {
            key: "REG_2"
            value: 320
          }
          value {
            key: "REG_3"
            value: 16384
          }
        }
      }
    }
    subg_attr {
      key: "runner"
      value {
        map_string_2_string_value {
          value {
            key: "ref"
            value: "libvart-cpu-runner.so"
          }
          value {
            key: "run"
            value: "libvart-dpu-runner.so"
          }
          value {
            key: "sim"
            value: "libvart-sim-runner.so"
          }
        }
      }
    }
    subg_attr {
      key: "workload"
      value {
        uint64_value: 835584
      }
    }
    subg_attr {
      key: "workload_on_arch"
      value {
        uint64_value: 2637824
      }
    }
    subg_child {
      subgraph_name: "subgraph_Net__input_0_upload_0"
      op_name: "Net__input_0_upload_0"
      subg_attr {
        key: "skip_code_gen"
        value {
          bool_value: true
        }
      }
      subg_attr {
        key: "workload"
        value {
          uint64_value: 0
        }
      }
      subg_attr {
        key: "workload_on_arch"
        value {
          uint64_value: 0
        }
      }
    }
    subg_child {
      subgraph_name: "subgraph_Net__Net_Conv2d_conv1__168"
      op_name: "Net__conv1_weight_new"
      op_name: "Net__conv1_bias_new"
      op_name: "Net__Net_Conv2d_conv1__168"
      subg_attr {
        key: "mc_code"
        value {
          bytes_value {
            value: bytes = 820 md5sum = 2b2b08ca1f02cd65f09a5c6348a02890
            head: 
            0x5625b063a2c0 00000000: 0040 1801 01fc 0000 0000 0000 00fc 0000
            0x5625b063a2d0 00000010: 0000 0000 0014 0000 0000 0190 001c 4000
            0x5625b063a2e0 00000020: 3f00 4000 030c 0100 0000 6001 0400 0000
            0x5625b063a2f0 00000030: 0000 1401 003c 0000 3f10 0000 043c 0000
            0x5625b063a300 00000040: 0000 0000 0000 0000 0000 1001 0000 0000
            0x5625b063a310 00000050: 0000 0000 0f10 0008 0200 0013 3e00 0000
            0x5625b063a320 00000060: 0040 1001 0000 0000 0000 0000 0f10 0008
            0x5625b063a330 00000070: 0200 0013 4e00 0000 0080 1001 0000 0000
            0x5625b063a340 00000080: 0000 0000 0f10 0008 0200 0013 5e00 0000
            0x5625b063a350 00000090: 00c0 1001 0000 0000 0000 0000 0f10 0008
            tail: 
            0x5625b063a554 00000000: 03fc 0000 0ffc 0000 0300 0000 0020 0000
            0x5625b063a564 00000010: 4040 2242 03fc 0000 0ffc 0000 0300 0000
            0x5625b063a574 00000020: 0024 0000 4080 2242 03fc 0000 0ffc 0000
            0x5625b063a584 00000030: 0300 0000 0028 0000 40c0 2242 03fc 0000
            0x5625b063a594 00000040: 0ffc 0000 0300 0000 002c 0000 4000 2342
            0x5625b063a5a4 00000050: 03fc 0000 0ffc 0000 0300 0000 0030 0000
            0x5625b063a5b4 00000060: 4040 2342 03fc 0000 0ffc 0000 0300 0000
            0x5625b063a5c4 00000070: 0034 0000 4080 2342 03fc 0000 0ffc 0000
            0x5625b063a5d4 00000080: 0300 0000 0038 0000 40c0 2342 03fc 0000
            0x5625b063a5e4 00000090: 0ffc 0000 0300 0000 003c 0000 0000 2072
            
          }
        }
      }
      subg_attr {
        key: "mc_code_preload"
        value {
          bytes_value {
          }
        }
      }
      subg_attr {
        key: "workload"
        value {
          uint64_value: 835584
        }
      }
      subg_attr {
        key: "workload_on_arch"
        value {
          uint64_value: 2637824
        }
      }
    }
    subg_child {
      subgraph_name: "subgraph_Net__Net_Conv2d_conv1__168_download_0"
      op_name: "Net__Net_Conv2d_conv1__168_download_0"
      subg_attr {
        key: "workload"
        value {
          uint64_value: 0
        }
      }
      subg_attr {
        key: "workload_on_arch"
        value {
          uint64_value: 0
        }
      }
    }
  }
  subg_child {
    subgraph_name: "subgraph_Net__Net_Conv2d_conv1__168_fix_Net__Net_Tanh_tanh__input_3"
    op_name: "Net__Net_Conv2d_conv1__168_fix_Net__Net_Tanh_tanh__input_3"
    op_name: "Net__Net_Tanh_tanh__input_3"
    op_name: "Net__Net_Tanh_tanh__input_3_fix"
    subg_attr {
      key: "device"
      value {
        string_value: "CPU"
      }
    }
    subg_attr {
      key: "runner"
      value {
        map_string_2_string_value {
          value {
            key: "ref"
            value: "libvart-cpu-runner.so"
          }
          value {
            key: "run"
            value: "libvart-cpu-runner.so"
          }
          value {
            key: "sim"
            value: "libvart-cpu-runner.so"
          }
        }
      }
    }
    subg_attr {
      key: "workload"
      value {
        uint64_value: 0
      }
    }
    subg_attr {
      key: "workload_on_arch"
      value {
        uint64_value: 0
      }
    }
  }
  subg_child {
    subgraph_name: "subgraph_Net__Net_Conv2d_conv3__188"
    subg_attr {
      key: "children_topological_sort"
      value {
        string_vec_value {
          value: "subgraph_Net__Net_Conv2d_conv3__188"
        }
      }
    }
    subg_attr {
      key: "debug_mode"
      value {
        string_value: "function"
      }
    }
    subg_attr {
      key: "device"
      value {
        string_value: "DPU"
      }
    }
    subg_attr {
      key: "dpu_fingerprint"
      value {
        uint64_value: 433190036771510369
      }
    }
    subg_attr {
      key: "dpu_name"
      value {
        string_value: "DPUCVDX8G_ISA3_C32B6"
      }
    }
    subg_attr {
      key: "if_prefetch"
      value {
        bool_value: true
      }
    }
    subg_attr {
      key: "mc_code"
      value {
        bytes_value {
          value: bytes = 820 md5sum = a4363dda6e4ca0648243183f91331395
          head: 
          0x5625b063a2c0 00000000: 0040 1801 017c 0000 0000 0000 007c 0000
          0x5625b063a2d0 00000010: 0000 0000 0048 0000 0040 0190 031c 2200
          0x5625b063a2e0 00000020: 1f00 4000 010c 4000 0300 0000 2300 0000
          0x5625b063a2f0 00000030: 0000 1401 03fc 0000 1f8c 0000 08fc 0000
          0x5625b063a300 00000040: 0000 0000 0000 0000 0000 1001 03fc 0000
          0x5625b063a310 00000050: 0000 0000 0ffc 0000 0200 0000 0000 0000
          0x5625b063a320 00000060: 0040 1001 03fc 0000 0000 0000 0ffc 0000
          0x5625b063a330 00000070: 0200 0000 0004 0000 0080 1001 03fc 0000
          0x5625b063a340 00000080: 0000 0000 0ffc 0000 0200 0000 0008 0000
          0x5625b063a350 00000090: 00c0 1001 03fc 0000 0000 0000 0ffc 0000
          tail: 
          0x5625b063a554 00000000: 017c 0000 0f7c 0000 0300 0000 0010 0000
          0x5625b063a564 00000010: 2040 2242 017c 0000 0f7c 0000 0300 0000
          0x5625b063a574 00000020: 0012 0000 2080 2242 017c 0000 0f7c 0000
          0x5625b063a584 00000030: 0300 0000 0014 0000 20c0 2242 017c 0000
          0x5625b063a594 00000040: 0f7c 0000 0300 0000 0016 0000 2000 2342
          0x5625b063a5a4 00000050: 017c 0000 0f7c 0000 0300 0000 0018 0000
          0x5625b063a5b4 00000060: 2040 2342 017c 0000 0f7c 0000 0300 0000
          0x5625b063a5c4 00000070: 001a 0000 2080 2342 017c 0000 0f7c 0000
          0x5625b063a5d4 00000080: 0300 0000 001c 0000 20c0 2342 017c 0000
          0x5625b063a5e4 00000090: 0f7c 0000 0300 0000 001e 0000 0000 2072
          
        }
      }
    }
    subg_attr {
      key: "mc_code_preload"
      value {
        bytes_value {
        }
      }
    }
    subg_attr {
      key: "reg_id_to_context_type"
      value {
        map_string_2_string_value {
          value {
            key: "REG_0"
            value: "CONST"
          }
          value {
            key: "REG_2"
            value: "DATA"
          }
          value {
            key: "REG_3"
            value: "DATA"
          }
        }
      }
    }
    subg_attr {
      key: "reg_id_to_context_type_v2"
      value {
        map_string_2_string_value {
          value {
            key: "REG_0"
            value: "CONST"
          }
          value {
            key: "REG_2"
            value: "INTERFACE"
          }
          value {
            key: "REG_3"
            value: "INTERFACE"
          }
        }
      }
    }
    subg_attr {
      key: "reg_id_to_hw_segment"
      value {
        map_string_2_string_value {
          value {
            key: "REG_0"
            value: "W0"
          }
          value {
            key: "REG_2"
            value: "D0"
          }
          value {
            key: "REG_3"
            value: "D0"
          }
        }
      }
    }
    subg_attr {
      key: "reg_id_to_parameter_value"
      value {
        map_string_2_bytes_value {
          value {
            key: "REG_0"
            value {
              value: bytes = 18496 md5sum = 169ae00c3fce63c3a58a7b1a6eb60017
              head: 
              0x5625b06abd90 00000000: 08f8 fcee faf3 2218 ede1 0c1d 12f3 090d
              0x5625b06abda0 00000010: 1334 0d01 f6e8 1e1a 101a 0800 01be 0032
              0x5625b06abdb0 00000020: 00e5 0106 0bde 2ad0 fcf9 fe0c 0104 1013
              0x5625b06abdc0 00000030: ebf9 251e fd31 1a17 0203 000c 10f4 16f9
              0x5625b06abdd0 00000040: 03f8 0316 c70c 05e6 25ea e805 f705 f5f7
              0x5625b06abde0 00000050: 27f3 eaed 00ec 00ef f317 f5eb f09c efbe
              0x5625b06abdf0 00000060: f604 fa11 fc0b 0006 25fc dfe4 f217 fed6
              0x5625b06abe00 00000070: f4eb fc1b 06fd fb06 dcfd 1303 f8ec 1913
              0x5625b06abe10 00000080: 17f0 f30b 0cd9 0bed db16 06ec 05f7 ef09
              0x5625b06abe20 00000090: f7fe e3e8 1a04 2af2 0608 2226 e5ea d018
              tail: 
              0x5625b06b0530 00000000: 1cd9 150e 1911 1e01 e1fa e7fe f7ec 3422
              0x5625b06b0540 00000010: 0302 02e4 0213 fe05 faf4 fc14 00ef e001
              0x5625b06b0550 00000020: ed01 1906 fff6 2ff4 0005 1c1f 26e3 0eff
              0x5625b06b0560 00000030: 00db 20f0 faf9 f30f f003 150f 06f8 dbfa
              0x5625b06b0570 00000040: 0c04 f0d9 eef3 ef16 0aee ee0d eefe 05e4
              0x5625b06b0580 00000050: f80b 0105 13e9 01fd f118 f2e9 f00f 2aff
              0x5625b06b0590 00000060: 10ee fc1f 12fd e3f9 f704 07b4 0f21 eff5
              0x5625b06b05a0 00000070: 0601 ebde f61f 01df 0be6 0127 fef3 15e1
              0x5625b06b05b0 00000080: 0000 0000 0000 0000 0000 0000 0000 0000
              0x5625b06b05c0 00000090: 0000 0000 0000 0000 0000 0000 0000 0000
              
            }
          }
        }
      }
    }
    subg_attr {
      key: "reg_id_to_size"
      value {
        map_string_2_int32_value {
          value {
            key: "REG_0"
            value: 18496
          }
          value {
            key: "REG_2"
            value: 16384
          }
          value {
            key: "REG_3"
            value: 8192
          }
        }
      }
    }
    subg_attr {
      key: "runner"
      value {
        map_string_2_string_value {
          value {
            key: "ref"
            value: "libvart-cpu-runner.so"
          }
          value {
            key: "run"
            value: "libvart-dpu-runner.so"
          }
          value {
            key: "sim"
            value: "libvart-sim-runner.so"
          }
        }
      }
    }
    subg_attr {
      key: "workload"
      value {
        uint64_value: 9445376
      }
    }
    subg_attr {
      key: "workload_on_arch"
      value {
        uint64_value: 9445376
      }
    }
    subg_child {
      subgraph_name: "subgraph_Net__Net_Tanh_tanh__input_3_fix_upload_0"
      op_name: "Net__Net_Tanh_tanh__input_3_fix_upload_0"
      subg_attr {
        key: "skip_code_gen"
        value {
          bool_value: true
        }
      }
      subg_attr {
        key: "workload"
        value {
          uint64_value: 0
        }
      }
      subg_attr {
        key: "workload_on_arch"
        value {
          uint64_value: 0
        }
      }
    }
    subg_child {
      subgraph_name: "subgraph_Net__Net_Conv2d_conv3__188"
      op_name: "Net__conv3_weight_new"
      op_name: "Net__conv3_bias_new"
      op_name: "Net__Net_Conv2d_conv3__188"
      subg_attr {
        key: "mc_code"
        value {
          bytes_value {
            value: bytes = 820 md5sum = a4363dda6e4ca0648243183f91331395
            head: 
            0x5625b063a2c0 00000000: 0040 1801 017c 0000 0000 0000 007c 0000
            0x5625b063a2d0 00000010: 0000 0000 0048 0000 0040 0190 031c 2200
            0x5625b063a2e0 00000020: 1f00 4000 010c 4000 0300 0000 2300 0000
            0x5625b063a2f0 00000030: 0000 1401 03fc 0000 1f8c 0000 08fc 0000
            0x5625b063a300 00000040: 0000 0000 0000 0000 0000 1001 03fc 0000
            0x5625b063a310 00000050: 0000 0000 0ffc 0000 0200 0000 0000 0000
            0x5625b063a320 00000060: 0040 1001 03fc 0000 0000 0000 0ffc 0000
            0x5625b063a330 00000070: 0200 0000 0004 0000 0080 1001 03fc 0000
            0x5625b063a340 00000080: 0000 0000 0ffc 0000 0200 0000 0008 0000
            0x5625b063a350 00000090: 00c0 1001 03fc 0000 0000 0000 0ffc 0000
            tail: 
            0x5625b063a554 00000000: 017c 0000 0f7c 0000 0300 0000 0010 0000
            0x5625b063a564 00000010: 2040 2242 017c 0000 0f7c 0000 0300 0000
            0x5625b063a574 00000020: 0012 0000 2080 2242 017c 0000 0f7c 0000
            0x5625b063a584 00000030: 0300 0000 0014 0000 20c0 2242 017c 0000
            0x5625b063a594 00000040: 0f7c 0000 0300 0000 0016 0000 2000 2342
            0x5625b063a5a4 00000050: 017c 0000 0f7c 0000 0300 0000 0018 0000
            0x5625b063a5b4 00000060: 2040 2342 017c 0000 0f7c 0000 0300 0000
            0x5625b063a5c4 00000070: 001a 0000 2080 2342 017c 0000 0f7c 0000
            0x5625b063a5d4 00000080: 0300 0000 001c 0000 20c0 2342 017c 0000
            0x5625b063a5e4 00000090: 0f7c 0000 0300 0000 001e 0000 0000 2072
            
          }
        }
      }
      subg_attr {
        key: "mc_code_preload"
        value {
          bytes_value {
          }
        }
      }
      subg_attr {
        key: "workload"
        value {
          uint64_value: 9445376
        }
      }
      subg_attr {
        key: "workload_on_arch"
        value {
          uint64_value: 9445376
        }
      }
    }
    subg_child {
      subgraph_name: "subgraph_Net__Net_Conv2d_conv3__188_download_0"
      op_name: "Net__Net_Conv2d_conv3__188_download_0"
      subg_attr {
        key: "workload"
        value {
          uint64_value: 0
        }
      }
      subg_attr {
        key: "workload_on_arch"
        value {
          uint64_value: 0
        }
      }
    }
  }
  subg_child {
    subgraph_name: "subgraph_Net__Net_Conv2d_conv3__188_fix_Net__Net_Tanh_tanh__input"
    op_name: "Net__Net_Conv2d_conv3__188_fix_Net__Net_Tanh_tanh__input"
    op_name: "Net__Net_Tanh_tanh__input"
    op_name: "Net__Net_Tanh_tanh__input_fix"
    subg_attr {
      key: "device"
      value {
        string_value: "CPU"
      }
    }
    subg_attr {
      key: "runner"
      value {
        map_string_2_string_value {
          value {
            key: "ref"
            value: "libvart-cpu-runner.so"
          }
          value {
            key: "run"
            value: "libvart-cpu-runner.so"
          }
          value {
            key: "sim"
            value: "libvart-cpu-runner.so"
          }
        }
      }
    }
    subg_attr {
      key: "workload"
      value {
        uint64_value: 0
      }
    }
    subg_attr {
      key: "workload_on_arch"
      value {
        uint64_value: 0
      }
    }
  }
  subg_child {
    subgraph_name: "subgraph_Net__Net_Conv2d_conv4__208"
    subg_attr {
      key: "children_topological_sort"
      value {
        string_vec_value {
          value: "subgraph_Net__Net_Conv2d_conv4__208"
        }
      }
    }
    subg_attr {
      key: "debug_mode"
      value {
        string_value: "function"
      }
    }
    subg_attr {
      key: "device"
      value {
        string_value: "DPU"
      }
    }
    subg_attr {
      key: "dpu_fingerprint"
      value {
        uint64_value: 433190036771510369
      }
    }
    subg_attr {
      key: "dpu_name"
      value {
        string_value: "DPUCVDX8G_ISA3_C32B6"
      }
    }
    subg_attr {
      key: "if_prefetch"
      value {
        bool_value: true
      }
    }
    subg_attr {
      key: "mc_code"
      value {
        bytes_value {
          value: bytes = 1972 md5sum = 585f3bef058d8cc21829653c06049b03
          head: 
          0x5625b0683a40 00000000: 0040 1801 01fc 0100 0000 0000 00fc 0100
          0x5625b0683a50 00000010: 0000 0000 0012 0000 0020 0190 011c 2200
          0x5625b0683a60 00000020: 1f00 c001 010c 0000 0100 0000 1100 0000
          0x5625b0683a70 00000030: 0000 1401 017c 0000 0344 0000 087c 0000
          0x5625b0683a80 00000040: 0000 0000 0000 0000 1200 1401 017c 0000
          0x5625b0683a90 00000050: 0344 0000 087c 0000 0000 0000 8004 0000
          0x5625b0683aa0 00000060: 2400 1401 017c 0000 0344 0000 087c 0000
          0x5625b0683ab0 00000070: 0000 0000 0009 0000 3600 1401 017c 0000
          0x5625b0683ac0 00000080: 0344 0000 087c 0000 0000 0000 800d 0000
          0x5625b0683ad0 00000090: 0000 1001 017c 0000 0000 0000 0f7c 0000
          tail: 
          0x5625b0684154 00000000: 0104 0000 0f00 0000 0300 0000 2102 0000
          0x5625b0684164 00000010: e040 2242 0104 0000 0f00 0000 0300 0000
          0x5625b0684174 00000020: 6102 0000 e080 2242 0104 0000 0f00 0000
          0x5625b0684184 00000030: 0300 0000 a102 0000 e0c0 2242 0104 0000
          0x5625b0684194 00000040: 0f00 0000 0300 0000 e102 0000 e000 2342
          0x5625b06841a4 00000050: 0104 0000 0f00 0000 0300 0000 2103 0000
          0x5625b06841b4 00000060: e040 2342 0104 0000 0f00 0000 0300 0000
          0x5625b06841c4 00000070: 6103 0000 e080 2342 0104 0000 0f00 0000
          0x5625b06841d4 00000080: 0300 0000 a103 0000 e0c0 2342 0104 0000
          0x5625b06841e4 00000090: 0f00 0000 0300 0000 e103 0000 0000 2072
          
        }
      }
    }
    subg_attr {
      key: "mc_code_preload"
      value {
        bytes_value {
        }
      }
    }
    subg_attr {
      key: "reg_id_to_context_type"
      value {
        map_string_2_string_value {
          value {
            key: "REG_0"
            value: "CONST"
          }
          value {
            key: "REG_2"
            value: "DATA"
          }
          value {
            key: "REG_3"
            value: "DATA"
          }
        }
      }
    }
    subg_attr {
      key: "reg_id_to_context_type_v2"
      value {
        map_string_2_string_value {
          value {
            key: "REG_0"
            value: "CONST"
          }
          value {
            key: "REG_2"
            value: "INTERFACE"
          }
          value {
            key: "REG_3"
            value: "INTERFACE"
          }
        }
      }
    }
    subg_attr {
      key: "reg_id_to_hw_segment"
      value {
        map_string_2_string_value {
          value {
            key: "REG_0"
            value: "W0"
          }
          value {
            key: "REG_2"
            value: "D0"
          }
          value {
            key: "REG_3"
            value: "D0"
          }
        }
      }
    }
    subg_attr {
      key: "reg_id_to_parameter_value"
      value {
        map_string_2_bytes_value {
          value {
            key: "REG_0"
            value {
              value: bytes = 4672 md5sum = bec6d0610d27063dbd9c124e7fba7bf1
              head: 
              0x5625b06a8790 00000000: 0dee 11fd 0c0d 0703 ec0a 01e7 0ef6 290c
              0x5625b06a87a0 00000010: 0000 0000 0000 0000 0000 0000 0000 0000
              0x5625b06a87b0 00000020: 0000 0000 0000 0000 0000 0000 0000 0000
              0x5625b06a87c0 00000030: 0000 0000 0000 0000 0000 0000 0000 0000
              0x5625b06a87d0 00000040: e804 1f0c f81f ee0b 0c07 ff16 faff 0007
              0x5625b06a87e0 00000050: 0000 0000 0000 0000 0000 0000 0000 0000
              0x5625b06a87f0 00000060: 0000 0000 0000 0000 0000 0000 0000 0000
              0x5625b06a8800 00000070: 0000 0000 0000 0000 0000 0000 0000 0000
              0x5625b06a8810 00000080: 0327 ea10 32e4 f205 30e5 3219 23de c9ee
              0x5625b06a8820 00000090: 0000 0000 0000 0000 0000 0000 0000 0000
              tail: 
              0x5625b06a9930 00000000: 0000 0000 0000 0000 0000 0000 0000 0000
              0x5625b06a9940 00000010: 0000 0000 0000 0000 0000 0000 0000 0000
              0x5625b06a9950 00000020: 0809 0615 f102 e900 f1ef f2e3 240c 0613
              0x5625b06a9960 00000030: 0000 0000 0000 0000 0000 0000 0000 0000
              0x5625b06a9970 00000040: 0000 0000 0000 0000 0000 0000 0000 0000
              0x5625b06a9980 00000050: 0000 0000 0000 0000 0000 0000 0000 0000
              0x5625b06a9990 00000060: 7c00 0000 0000 0000 0000 0000 0000 0000
              0x5625b06a99a0 00000070: 6500 0000 0000 0000 0000 0000 0000 0000
              0x5625b06a99b0 00000080: 5d00 0000 0000 0000 0000 0000 0000 0000
              0x5625b06a99c0 00000090: 6800 0000 0000 0000 0000 0000 0000 0000
              
            }
          }
        }
      }
    }
    subg_attr {
      key: "reg_id_to_size"
      value {
        map_string_2_int32_value {
          value {
            key: "REG_0"
            value: 4672
          }
          value {
            key: "REG_2"
            value: 8192
          }
          value {
            key: "REG_3"
            value: 1024
          }
        }
      }
    }
    subg_attr {
      key: "runner"
      value {
        map_string_2_string_value {
          value {
            key: "ref"
            value: "libvart-cpu-runner.so"
          }
          value {
            key: "run"
            value: "libvart-dpu-runner.so"
          }
          value {
            key: "sim"
            value: "libvart-sim-runner.so"
          }
        }
      }
    }
    subg_attr {
      key: "workload"
      value {
        uint64_value: 590848
      }
    }
    subg_attr {
      key: "workload_on_arch"
      value {
        uint64_value: 4726784
      }
    }
    subg_child {
      subgraph_name: "subgraph_Net__Net_Tanh_tanh__input_fix_upload_0"
      op_name: "Net__Net_Tanh_tanh__input_fix_upload_0"
      subg_attr {
        key: "skip_code_gen"
        value {
          bool_value: true
        }
      }
      subg_attr {
        key: "workload"
        value {
          uint64_value: 0
        }
      }
      subg_attr {
        key: "workload_on_arch"
        value {
          uint64_value: 0
        }
      }
    }
    subg_child {
      subgraph_name: "subgraph_Net__Net_Conv2d_conv4__208"
      op_name: "Net__conv4_weight_new"
      op_name: "Net__conv4_bias_new"
      op_name: "Net__Net_Conv2d_conv4__208"
      op_name: "Net__Net_PixelShuffle_pixel_shuffle__210_convert_to_tile"
      subg_attr {
        key: "mc_code"
        value {
          bytes_value {
            value: bytes = 1972 md5sum = 585f3bef058d8cc21829653c06049b03
            head: 
            0x5625b0683a40 00000000: 0040 1801 01fc 0100 0000 0000 00fc 0100
            0x5625b0683a50 00000010: 0000 0000 0012 0000 0020 0190 011c 2200
            0x5625b0683a60 00000020: 1f00 c001 010c 0000 0100 0000 1100 0000
            0x5625b0683a70 00000030: 0000 1401 017c 0000 0344 0000 087c 0000
            0x5625b0683a80 00000040: 0000 0000 0000 0000 1200 1401 017c 0000
            0x5625b0683a90 00000050: 0344 0000 087c 0000 0000 0000 8004 0000
            0x5625b0683aa0 00000060: 2400 1401 017c 0000 0344 0000 087c 0000
            0x5625b0683ab0 00000070: 0000 0000 0009 0000 3600 1401 017c 0000
            0x5625b0683ac0 00000080: 0344 0000 087c 0000 0000 0000 800d 0000
            0x5625b0683ad0 00000090: 0000 1001 017c 0000 0000 0000 0f7c 0000
            tail: 
            0x5625b0684154 00000000: 0104 0000 0f00 0000 0300 0000 2102 0000
            0x5625b0684164 00000010: e040 2242 0104 0000 0f00 0000 0300 0000
            0x5625b0684174 00000020: 6102 0000 e080 2242 0104 0000 0f00 0000
            0x5625b0684184 00000030: 0300 0000 a102 0000 e0c0 2242 0104 0000
            0x5625b0684194 00000040: 0f00 0000 0300 0000 e102 0000 e000 2342
            0x5625b06841a4 00000050: 0104 0000 0f00 0000 0300 0000 2103 0000
            0x5625b06841b4 00000060: e040 2342 0104 0000 0f00 0000 0300 0000
            0x5625b06841c4 00000070: 6103 0000 e080 2342 0104 0000 0f00 0000
            0x5625b06841d4 00000080: 0300 0000 a103 0000 e0c0 2342 0104 0000
            0x5625b06841e4 00000090: 0f00 0000 0300 0000 e103 0000 0000 2072
            
          }
        }
      }
      subg_attr {
        key: "mc_code_preload"
        value {
          bytes_value {
          }
        }
      }
      subg_attr {
        key: "workload"
        value {
          uint64_value: 590848
        }
      }
      subg_attr {
        key: "workload_on_arch"
        value {
          uint64_value: 4726784
        }
      }
    }
    subg_child {
      subgraph_name: "subgraph_Net__Net_PixelShuffle_pixel_shuffle__210_convert_to_tile_download_0"
      op_name: "Net__Net_PixelShuffle_pixel_shuffle__210_convert_to_tile_download_0"
      subg_attr {
        key: "workload"
        value {
          uint64_value: 0
        }
      }
      subg_attr {
        key: "workload_on_arch"
        value {
          uint64_value: 0
        }
      }
    }
  }
  subg_child {
    subgraph_name: "subgraph_Net__Net_PixelShuffle_pixel_shuffle__210_fix_"
    op_name: "Net__Net_PixelShuffle_pixel_shuffle__210_fix_"
    subg_attr {
      key: "device"
      value {
        string_value: "CPU"
      }
    }
    subg_attr {
      key: "runner"
      value {
        map_string_2_string_value {
          value {
            key: "ref"
            value: "libvart-cpu-runner.so"
          }
          value {
            key: "run"
            value: "libvart-cpu-runner.so"
          }
          value {
            key: "sim"
            value: "libvart-cpu-runner.so"
          }
        }
      }
    }
    subg_attr {
      key: "workload"
      value {
        uint64_value: 0
      }
    }
    subg_attr {
      key: "workload_on_arch"
      value {
        uint64_value: 0
      }
    }
  }
}
graph_attr {
  key: "files_md5sum"
  value {
    map_string_2_string_value {
      value {
        key: "/workspace/./build/quant_model/Net_int.xmodel"
        value: "7f42965dee545d74f4fdfda496c6e371"
      }
    }
  }
}
graph_attr {
  key: "libs_info"
  value {
    map_string_2_string_value {
      value {
        key: "xcompiler.2.5.0"
        value: "54ab96213ea1331b60d985035eb836d931e0afea"
      }
      value {
        key: "xcompiler.2.5.0 : target-factory.2.5.0"
        value: "9e04a0e4c5f6c6252d7d269813cdb70a67b79b16"
      }
      value {
        key: "xcompiler.2.5.0 : xir.2.5.0"
        value: "7387c9cc7f9ad438b09006f11854ac7bab176a86"
      }
    }
  }
}
op_defs {
  name: "scale"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  input_args {
    name: "scale"
    data_type: 4
    annotation: "1-dimension, channel-wise."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 4
    annotation: "1-dimension, channel-wise."
  }
  attrs {
    name: "axis"
    occur_type: OPTIONAL
    default_value {
      int32_value: -1
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nthe axis of the input to implement scale"
  }
  annotation: "This function computes the channel-wise dot product and adds the bias. For example, axis = -1:\n\n    output[b, h, w, c] = input[b, h, w, c] * scale[c] + bias[c]\n"
}
op_defs {
  name: "exp"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "This function computes the exponential of the input tensor element-wise.\n\n    f(x) = exp(x)\n"
}
op_defs {
  name: "tile-fix"
  input_args {
    name: "input"
    data_type: 2
    annotation: "4-dimension, N H W C"
  }
  attrs {
    name: "reverse"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nif reverse"
  }
  attrs {
    name: "stride"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nstride for feature maps"
  }
}
op_defs {
  name: "matmul"
  input_args {
    name: "input"
    occur_type: REQUIRED_AND_REPEATED
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 4
    annotation: "1-dimension"
  }
  attrs {
    name: "transpose_a"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nIf true, input[0] is transposed before multiplication.\n\ntranspose(input[0]):\n\n    [..., a, b] -> [..., b, a]\n"
  }
  attrs {
    name: "transpose_b"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nIf true, input[1] is transposed before multiplication.\n\ntranspose(input[1]):\n\n    [..., b, c] -> [..., c, b]\n"
  }
  annotation: "This operator is batched matmul.\n\n    input[0] : [..., a, b]\n    input[1] : [..., b, c]\n    output   : [..., a, c]\n    output[..., a, c] = sum_{i}\n                      input[0][..., a, i] * input[1][..., i, b]\nIn this operator, ... denotes non-matrix dimensions,\nand non-matrix dimensions are broadcasted.\nFor example,  if input[0].shape is `(1, j, m, n)`, and the other is `(k, 1, n, p)`, the out.shape would be `(k, j, m, p)`."
}
op_defs {
  name: "stack"
  input_args {
    name: "input"
    occur_type: REQUIRED_AND_REPEATED
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "axis"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nDimension along which to pack. Negative values wrap around, so the valid range is [-(R+1), R+1)"
  }
  annotation: "Stacks a list of `rank-R` tensors into one `rank-(R+1)` tensor.\n\nFor example, given a list of length N of tensors of shape `(A, B, C)`;\n\nif axis == 0 then the output tensor will have the shape `(N, A, B, C)`.\n\nif axis == 1 then the output tensor will have the shape `(A, N, B, C)`."
}
op_defs {
  name: "strided_slice"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "begin"
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nstart location of slicing"
  }
  attrs {
    name: "end"
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nend location of slicing"
  }
  attrs {
    name: "strides"
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nstrides of slicing"
  }
  annotation: "This operator is NumPy-style slicing syntax,\n\n    output = input[begin:end:strides]\n"
}
op_defs {
  name: "softmax"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "axis"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nthe dimension softmax would be performed on."
  }
  annotation: "Softmax Operator performs softmax along the dimension of axis.\n\n    f(o) = exp(o) / sum_{i}(exp(i))"
}
op_defs {
  name: "batchnorm"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  input_args {
    name: "gamma"
    data_type: 4
    annotation: "`[in.shape[axis]]`"
  }
  input_args {
    name: "beta"
    data_type: 4
    annotation: "`[in.shape[axis]]`"
  }
  input_args {
    name: "moving_mean"
    data_type: 4
    annotation: "`[in.shape[axis]]`"
  }
  input_args {
    name: "moving_var"
    data_type: 4
    annotation: "`[in.shape[axis]]`"
  }
  attrs {
    name: "axis"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nthe axis of the input to implement batchnorm"
  }
  attrs {
    name: "epsilon"
    default_value {
      float_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `float`\n\na value added to the denominator for numerical stability"
  }
  annotation: "implements batchnorm along the last dimension of input feature maps.\n\n    output = (input - moving_mean) /\n             sqrt(moving_var + epsilon) * gamma + beta"
}
op_defs {
  name: "pixel-shuffle-fix"
  input_args {
    name: "input"
    data_type: 4
    annotation: "`[batch, in_height, in_width, in_channels]`."
  }
  attrs {
    name: "scale"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nscale for reorg"
  }
  attrs {
    name: "reverse"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nreorg or reversed reorg"
  }
}
op_defs {
  name: "reorg-fix"
  input_args {
    name: "input"
    data_type: 4
    annotation: "`[batch, in_height, in_width, in_channels]`."
  }
  attrs {
    name: "scale"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nscale for reorg"
  }
  attrs {
    name: "reverse"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nreorg or reversed reorg"
  }
}
op_defs {
  name: "reorg"
  input_args {
    name: "input"
    data_type: 4
    annotation: "`[batch, in_height, in_width, in_channels]`."
  }
  attrs {
    name: "scale"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nscale for reorg"
  }
  attrs {
    name: "reverse"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nreorg or reversed reorg"
  }
  annotation: "Reorg Operator in YOLO.The implementations can be seen in https://github.com/intel/caffe/blob/master/include/caffe/layers/reorg_layer.hpp."
}
op_defs {
  name: "concat-fix"
  input_args {
    name: "input"
    occur_type: REQUIRED_AND_REPEATED
    data_type: 2
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "axis"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nDimension along which to concatenate."
  }
}
op_defs {
  name: "concat"
  input_args {
    name: "input"
    occur_type: REQUIRED_AND_REPEATED
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "axis"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nDimension along which to concatenate."
  }
  annotation: "Concatenates different feature maps along the dimension `axis`.\nAll dimensions except axis must be equal."
}
op_defs {
  name: "downsample-fix"
  input_args {
    name: "input"
    data_type: 2
    annotation: "The feature maps, can be x-dimension."
  }
  input_args {
    name: "size"
    occur_type: OPTIONAL
    annotation: "Constant values denotes the shape of the output feature maps."
  }
  attrs {
    name: "mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nNEAREST, BILINEAR or TRILINEAR"
  }
  attrs {
    name: "align_corners"
    occur_type: OPTIONAL
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nIf true, preserving the values at the corner pixels. Defaults to false."
  }
  attrs {
    name: "half_pixel_centers"
    occur_type: OPTIONAL
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nIf true, use half-pixel as centers."
  }
  attrs {
    name: "scale"
    default_value {
      float_vec_value {
      }
    }
    list_length: 2
    annotation: "`DataType` : `std::vector<float>` {scale_w, scale_h}"
  }
}
op_defs {
  name: "resize"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  input_args {
    name: "size"
    occur_type: OPTIONAL
    annotation: "Constant values denotes the shape of the output feature maps."
  }
  attrs {
    name: "mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nNEAREST, BILINEAR or TRILINEAR"
  }
  attrs {
    name: "align_corners"
    occur_type: OPTIONAL
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nIf true, preserving the values at the corner pixels. Defaults to false."
  }
  attrs {
    name: "half_pixel_centers"
    occur_type: OPTIONAL
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nIf true, use half-pixel as centers."
  }
  attrs {
    name: "scale"
    occur_type: OPTIONAL
    default_value {
      float_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<float>`\n\nConstant values denotes the scale to resize the input. scale = out / in"
  }
  annotation: "Operator resize the feature maps. For example, if the input is an image, and the shape of this image is [h, w, c], after 2d resize, the shape of the output image is [oh, ow, c].\n\n    scale = (align_corners && out > 1)\n            ? (in - 1) / (out - 1)\n            : in / out\nWhen given the index of output, how to find the corresponding input pixels:\n\n    scaler = half_pixel_centers\n             ? (out + 0.5) * scale - 0.5\n             : out * scale\n(1). for NEAREST resize:\n\n    w_idx[ow] = min((w - 1),\n                    align_corners ? round(scaler(ow))\n                                  : floor(scaler(ow)))\n    h_idx[oh] = min((h - 1),\n                    align_corners ? round(scaler(oh))\n                                  : floor(scaler(oh)))\n    resize[oh, ow, c] = image[h_idx[oh], w_idx[ow], c]\n(2). for BILINEAR resize:\n\n    top = floor(scaler(oh))\n    bottom = min(h - 1, top + 1)\n    left = floor(scaler(ow))\n    right = min(w - 1, left + 1)\n    x_lerp = scaler(ow) - left\n    y_lerp = scaler(oh) - top\n    reisze[oh, ow, c] = (image[top, left, c] * (1 - x_lerp) +\n                         image[top, right, c] * x_lerp) * (1 - y_lerp)\n                        (image[bottom, left, c] * (1 - x_lerp) +\n                         image[bottom, right, c] * x_lerp) * y_lerp\n"
}
op_defs {
  name: "pad-fix"
  input_args {
    name: "input"
    data_type: 2
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "paddings"
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\npad along different dimensions, the number of value in paddings should be 2 times the number of dimensions of input feature maps.The n-th dimension of the output feature maps equals to:\n\n    (n-th dim) out =\n        paddings[2n] + (n-th dim) in + paddings[2n + 1]"
  }
  attrs {
    name: "mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\n`CONSTANT`,`REFLECT` or `SYMMETRIC`"
  }
  attrs {
    name: "constant_values"
    occur_type: OPTIONAL
    default_value {
      bytes_value {
      }
    }
    annotation: "`Datatype`: `vector<char>`\n\nthe value set into the padded locations, 2 * len(paddings)"
  }
  annotation: "For example,\n\nif the mode = \"CONSTANT\"\n\n    input = [[1, 2],\n             [3, 4]]\n    paddings = [0, 1, 1, 0]\n    output = [[0, 1, 2],\n              [0, 3, 4],\n              [0, 0, 0]]\nif the mode = \"REFLECT\"\n\n    input = [[1, 2],\n             [3, 4]]\n    paddings = [0, 1, 1, 0]\n    output = [[2, 1, 2],\n              [4, 3, 4],\n              [2, 1, 2]]\nif the mode = \"SYMMETRIC\"\n\n    input = [[1, 2],\n             [3, 4]]\n    paddings = [0, 1, 1, 0]\n    output = [[1, 1, 2],\n              [3, 3, 4],\n              [3, 3, 4]]\n"
}
op_defs {
  name: "flatten"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "start_axis"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nstart axis to be flattened"
  }
  attrs {
    name: "end_axis"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nend axis to be flattened"
  }
  annotation: "For example:\n\n    input.shape  = [32, 5, 5, 2, 4]\n    start_axis = 1\n    end_axis = -1\n    output.shape = [32, 200]"
}
op_defs {
  name: "eltwise-fix"
  input_args {
    name: "input"
    occur_type: REQUIRED_AND_REPEATED
    data_type: 2
    annotation: "The feature maps, can be x-dimension. eltwise-fix operator implements element-wise operations."
  }
  attrs {
    name: "nonlinear"
    occur_type: OPTIONAL
    default_value {
      string_value: "NONE"
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nnonlinear type, \"NONE\", \"RELU\", \"PRELU\", \"LEAKYRELU\",\"RELU6\". Default is \"NONE\""
  }
  attrs {
    name: "type"
    occur_type: OPTIONAL
    default_value {
      string_value: "ADD"
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\neltwise type, \"ADD\", \"MUL\". Default is \"ADD\""
  }
}
op_defs {
  name: "transpose"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "order"
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nThe order to be transposed."
  }
  annotation: "For example:\n\n    input.shape  = [32, 2, 64, 4]\n    order = {0, 3, 2, 1}\n    output = input.transpose([0, 3, 2, 1]\n    output.shape = [32, 4, 64, 2]"
}
op_defs {
  name: "squeeze"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "axis"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nThe dimensions to be squeezed.\nIf axis is not specified, all dimensions equal to 1 would be squeezed."
  }
  annotation: "For example:\n\n    input.shape  = [32, 2, 1, 1]\n    axis = {2, 3}\n    output.shape = [32, 2]"
}
op_defs {
  name: "reshape-fix"
  input_args {
    name: "input"
    data_type: 2
    annotation: "x-dimension"
  }
  attrs {
    name: "shape"
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nshape"
  }
}
op_defs {
  name: "transposed-depthwise-conv3d"
  input_args {
    name: "input"
    data_type: 4
    annotation: "An input tensor with shape `[batch, in_height, in_width, depth, in_channels]`."
  }
  input_args {
    name: "weights"
    data_type: 4
    annotation: "A filter tensor with shape `[output_channels, kernel_height, kernel_width, kernel_depth, in_channels]`."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 4
    annotation: "A bias tensor with shape `[output_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height, kernel_depth}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height, stride_depth}`."
  }
  attrs {
    name: "dilation"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 1
        value: 1
        value: 1
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe dilation of the filter. The value must be: `{dilation_width, dilation_height, dilation_depth}`, The dilation in the batch or depth are 1 in default."
  }
  attrs {
    name: "pad_mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nWe support 4 padding mode: `FLOOR, CEIL, SAME, VALID`. For example, when you parsing models from other frameworks, `caffe, pytorch->\"FLOOR\", tensorflow->\"SAME\" or \"VALID\"`."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 6
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom, near, far}`.\n\nFor transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don\'t need to specify this attribute."
  }
  annotation: "Transposed depth-wise 3D convolution.\n\n"
}
op_defs {
  name: "conv2d-fix"
  input_args {
    name: "input"
    data_type: 2
    annotation: "An input tensor with shape `[batch, in_height, in_width, in_channels]`."
  }
  input_args {
    name: "weights"
    data_type: 2
    annotation: "A filter tensor with shape `[output_channels, kernel_height, kernel_width, in_channels]`."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 2
    annotation: "A bias tensor with shape `[output_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height}`."
  }
  attrs {
    name: "dilation"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 1
        value: 1
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 4
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.\n\nFor transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`."
  }
  attrs {
    name: "nonlinear"
    occur_type: OPTIONAL
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nnonlinear type, \"NONE\", \"RELU\", \"PRELU\", \"LEAKYRELU\",\"RELU6\",\"HSIGMOID\",\"HSWISH\"."
  }
  attrs {
    name: "hsigmoid_in"
    occur_type: OPTIONAL
    default_value {
      int32_value: -128
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nfix_point of hsigmoid"
  }
  attrs {
    name: "shift_hsigmoid"
    occur_type: OPTIONAL
    default_value {
      int32_value: -128
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nshift value after hsigmoid"
  }
  attrs {
    name: "shift_hswish"
    occur_type: OPTIONAL
    default_value {
      int32_value: -128
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nshift value after hswish"
  }
}
op_defs {
  name: "depthwise-conv3d-fix"
  input_args {
    name: "input"
    data_type: 2
    annotation: "An input tensor with shape `[batch, in_height, in_width, in_depth, in_channels]`."
  }
  input_args {
    name: "weights"
    data_type: 2
    annotation: "A filter tensor with shape `[output_channels, kernel_height, kernel_width, kernel_depth, in_channels]`."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 2
    annotation: "A bias tensor with shape `[output_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height}`."
  }
  attrs {
    name: "dilation"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 1
        value: 1
        value: 1
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 6
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.\n\nFor transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don\'t need to specify this attribute."
  }
  attrs {
    name: "nonlinear"
    occur_type: OPTIONAL
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nnonlinear type, \"NONE\", \"RELU\", \"PRELU\", \"LEAKYRELU\",\"RELU6\",\"HSIGMOID\",\"HSWISH\"."
  }
}
op_defs {
  name: "transposed-depthwise-conv2d-fix"
  input_args {
    name: "input"
    data_type: 2
    annotation: "An input tensor with shape `[batch, in_height, in_width, in_channels]`."
  }
  input_args {
    name: "weights"
    data_type: 2
    annotation: "A filter tensor with shape `[output_channels, kernel_height, kernel_width, in_channels]`."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 2
    annotation: "A bias tensor with shape `[output_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height}`."
  }
  attrs {
    name: "dilation"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 1
        value: 1
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 4
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.\n\nFor transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`."
  }
  attrs {
    name: "nonlinear"
    occur_type: OPTIONAL
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nnonlinear type, \"NONE\", \"RELU\", \"PRELU\", \"LEAKYRELU\",\"RELU6\",\"HSIGMOID\",\"HSWISH\"."
  }
}
op_defs {
  name: "transposed-conv2d-fix"
  input_args {
    name: "input"
    data_type: 2
    annotation: "An input tensor with shape `[batch, in_height, in_width, in_channels]`."
  }
  input_args {
    name: "weights"
    data_type: 2
    annotation: "A filter tensor with shape `[output_channels, kernel_height, kernel_width, in_channels]`."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 2
    annotation: "A bias tensor with shape `[output_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height}`."
  }
  attrs {
    name: "dilation"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 1
        value: 1
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 4
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.\n\nFor transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`."
  }
  attrs {
    name: "nonlinear"
    occur_type: OPTIONAL
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nnonlinear type, \"NONE\", \"RELU\", \"PRELU\", \"LEAKYRELU\",\"RELU6\",\"HSIGMOID\",\"HSWISH\"."
  }
}
op_defs {
  name: "relu"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "Computes the rectified linear element-wise:\n\n    f(x) = max(0, x).\n"
}
op_defs {
  name: "reduction_product"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "axis"
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nThe dimensions to reduce."
  }
  attrs {
    name: "keep_dims"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nspecify whether the reduced dimension is kept or not."
  }
  annotation: "Implement the product along each of the axis dimensions."
}
op_defs {
  name: "conv3d-fix"
  input_args {
    name: "input"
    data_type: 2
    annotation: "An input tensor with shape `[batch, in_height, in_width, in_depth, in_channels]`."
  }
  input_args {
    name: "weights"
    data_type: 2
    annotation: "A filter tensor with shape `[output_channels, kernel_height, kernel_width, kernel_depth, in_channels]`."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 2
    annotation: "A bias tensor with shape `[output_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height}`."
  }
  attrs {
    name: "dilation"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 1
        value: 1
        value: 1
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 6
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.\n\nFor transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don\'t need to specify this attribute."
  }
  attrs {
    name: "nonlinear"
    occur_type: OPTIONAL
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nnonlinear type, \"NONE\", \"RELU\", \"PRELU\", \"LEAKYRELU\",\"RELU6\",\"HSIGMOID\",\"HSWISH\"."
  }
  attrs {
    name: "hsigmoid_in"
    occur_type: OPTIONAL
    default_value {
      int32_value: -128
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nfix_point of hsigmoid"
  }
  attrs {
    name: "shift_hsigmoid"
    occur_type: OPTIONAL
    default_value {
      int32_value: -128
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nshift value after hsigmoid"
  }
  attrs {
    name: "shift_hswish"
    occur_type: OPTIONAL
    default_value {
      int32_value: -128
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nshift value after hswish"
  }
}
op_defs {
  name: "const"
  attrs {
    name: "shape"
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nThe shape of the output tensor"
  }
  attrs {
    name: "data_type"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nThe data type of the data of output feature maps, we use FLOAT32 as the default."
  }
  attrs {
    name: "data"
    default_value {
      bytes_value {
      }
    }
    annotation: "Constant values stored in this operator, \nfloat-point data in vector<char>.\n"
  }
  annotation: "A placeholder which stores the parameters, \nsuch as weights, bias, etc.\n\nHow to transform float-point values into vector<char>: \n\n    const std::vector<float> float_data = {...};\n    std::vector<char> data;\n    for (uint outer = 0; outer < float_data.size(); outer++)\n      for (auto inner = 0; inner < sizeof(float) / sizeof(char); inner++)\n        data.push_back(*(reinterpret_cast<char*>(&float_data) + inner));\n"
}
op_defs {
  name: "avgpool2d"
  input_args {
    name: "input"
    data_type: 4
    annotation: "An input tensor with shape `[batch, in_height, in_width, in_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height}`."
  }
  attrs {
    name: "pad_mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nWe support 4 padding mode: FLOOR, CEIL, SAME, VALID. For example, when you parsing models from other frameworks, `caffe->\"CEIL\",  tensorflow->\"SAME\" or \"VALID\", pytorch->\"FLOOR\"(default) or \"CEIL\".`"
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 4
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom}`."
  }
  attrs {
    name: "global"
    occur_type: OPTIONAL
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nGlobal pooling, if global is set to be true, the width and height of output feature maps would be {1, 1}."
  }
  attrs {
    name: "count_include_pad"
    occur_type: OPTIONAL
    default_value {
      bool_value: true
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nif count data in the pad position for avg_pool?For example, caffe is `true`, tensorflow is `false`,pytorch uses `true` as default."
  }
  attrs {
    name: "count_include_invalid"
    occur_type: OPTIONAL
    default_value {
      bool_value: true
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nif count data outside the padded input feature maps?For example, caffe is `false`, tf is `true`,pytorch is `true`."
  }
  annotation: "2D average-pooling.\n\n    output[batch, oh, ow, c] =\n        avg_{kw, kh} input[batch, strides[1] * oh + kh,\n           strides[0] * ow + kw, c] *\n(1). if pad_mode == \"`FLOOR`\":\n\n    output_shape = floor((input_shape + pad - kernel) / stride) + 1\n(2). if pad_mode == \"`CEIL`\":\n\n    output_shape = ceil((input_shape + pad - kernel) / stride) + 1\n(3). if pad_mode == \"`SAME`\":\n\n    output_shape = ceil((input_shape + pad) / stride)\n(4). if pad_mode == \"`VALID`\":\n\n    output_shape = ceil((input_shape + pad - kernel) / stride)\n"
}
op_defs {
  name: "transposed-depthwise-conv3d-fix"
  input_args {
    name: "input"
    data_type: 2
    annotation: "An input tensor with shape `[batch, in_height, in_width, in_depth, in_channels]`."
  }
  input_args {
    name: "weights"
    data_type: 2
    annotation: "A filter tensor with shape `[output_channels, kernel_height, kernel_width, kernel_depth, in_channels]`."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 2
    annotation: "A bias tensor with shape `[output_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height}`."
  }
  attrs {
    name: "dilation"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 1
        value: 1
        value: 1
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 6
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.\n\nFor transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don\'t need to specify this attribute."
  }
  attrs {
    name: "nonlinear"
    occur_type: OPTIONAL
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nnonlinear type, \"NONE\", \"RELU\", \"PRELU\", \"LEAKYRELU\",\"RELU6\",\"HSIGMOID\",\"HSWISH\"."
  }
}
op_defs {
  name: "hard-sigmoid"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "Computes the hard sigmoid function element-wise:\n\n    f(x) = relu6(x + 3) / 6.\n"
}
op_defs {
  name: "download"
  input_args {
    name: "input"
    data_type: 2
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "An interface operator that holds the data achieved by a DPU-runner, and would be sent to a CPU-runner later."
}
op_defs {
  name: "transposed-depthwise-conv2d"
  input_args {
    name: "input"
    data_type: 4
    annotation: "An input tensor with shape `[batch, in_height, in_width, in_channels]`."
  }
  input_args {
    name: "weights"
    data_type: 4
    annotation: "A filter tensor with shape `[output_channels, kernel_height, kernel_width, in_channels]`."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 4
    annotation: "A bias tensor with shape `[output_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height}`."
  }
  attrs {
    name: "dilation"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 1
        value: 1
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default."
  }
  attrs {
    name: "pad_mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nWe support 4 padding mode: `FLOOR, CEIL, SAME, VALID`. For example, when you parsing models from other frameworks, `caffe, pytorch->\"FLOOR\", tensorflow->\"SAME\" or \"VALID\"`."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 4
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.\n\nFor transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don\'t need to specify this attribute."
  }
  annotation: "2D depth-wise transposed convolution, our equivalent implementations::\nFirstly, we dilate the input feature maps by `stride`:\n\n    dilated_input[batch, h, w, c] =\n        ((h mod stride[1] == 0) && (w mod stride[0] == 0))\n        ? input[batch, h / stride[1], h / stride[0], ic]\n        : 0\nSecondly, we do 2D-convolution on the feature maps:\n\n    output[batch, oh, ow, b * c] =\n        sum_{kw, kh} dilated_input[batch, oh + kh, ow + kw, c] *\n                     filter[b, kh, kw, c]\nIf pad is set:\n\n    actual_padding[n] = kernel (h or w) - 1 - pad[n]\n    padded_dilated_input[batch, h - actual_padding[2], w - actual_padding[0], c] =\n        dilated_input[batch, h, w, c]\n    padded_dilated_input[batch, 0 : actual_padding[2], 0 : actual_padding[0], c] = 0\n    padded_dilated_input[batch, h + actual_padding[2] : h + actual_padding[2] + actual_padding[3]\n                         w + actual_padding[0] : w + actual_padding[0] + actual_padding[1], c] = 0\nAnd here is how to calculate the output shape according to the attributes:\n\n(1). if pad_mode == \"`FLOOR`\":\n\n    output_shape = (in_shape - 1) * stride + dilation * (kernel - 1) + 1 - pad\n(2). if pad_mode == \"`CEIL`\":\n\n    output_shape = (in_shape - 1) * stride + dilation * (kernel - 1) + 1 - pad\n(3). if pad_mode == \"`SAME`\":\n\n    output_shape = in_shape * stride\n(4). if pad_mode == \"`VALID`\":\n\n    output_shape = (in_shape - 1) * stride + kernel\n"
}
op_defs {
  name: "const-fix"
  attrs {
    name: "shape"
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nThe shape of the output tensor"
  }
  attrs {
    name: "data_type"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nThe data type of the data of output feature maps, we use FLOAT32 as the default."
  }
  attrs {
    name: "data"
    default_value {
      bytes_value {
      }
    }
    annotation: "Constant values stored in this operator, \nfixed-point data in vector<char>.\n"
  }
  annotation: "A placeholder which stores the parameters, \nsuch as fixed-point weights, bias, etc."
}
op_defs {
  name: "upload"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "An interface operator that holds the data achieved by a CPU-runner, and would be sent to a DPU-runner later."
}
op_defs {
  name: "random_standard_normal"
  attrs {
    name: "shape"
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nThe shape of the output tensor"
  }
  attrs {
    name: "data_type"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nThe data type of the data of output feature maps, we use FLOAT32 as the default."
  }
  attrs {
    name: "seed"
    occur_type: OPTIONAL
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`DataType`: `int`\n\nDefaults to 0. If either `seed` or `seed2` are set to be non-zero, the random number generator is seeded by the given seed. Otherwise, it is seeded by a random seed."
  }
  attrs {
    name: "seed2"
    occur_type: OPTIONAL
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`DataType`: `int`\n\nDefaults to 0. A second seed to avoid seed collision."
  }
  annotation: "Outputs random values from a normal distribution.\n\nAnd the generated values will have mean 0 and standard deviation 1."
}
op_defs {
  name: "data-fix"
  attrs {
    name: "shape"
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nThe shape of the output tensor"
  }
  attrs {
    name: "data_type"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nThe data type of the data of output feature maps, we use FLOAT32 as the default."
  }
  annotation: "A placeholder which stores the fixed-point input data, \ndata operator would always be fed by users."
}
op_defs {
  name: "fix2float"
  input_args {
    name: "input"
    data_type: 2
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "fix_point"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nThe fixed position of the output feature maps."
  }
  attrs {
    name: "bit_width"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nThe bit width of the output feature maps."
  }
  attrs {
    name: "round_mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nThe round mode function for transforming the float data.The round mode is one of `{STD_ROUND, DPU_ROUND, PY3_ROUND}`\n\n(1). If the round_mode = `STD_ROUND`:\n\n    f(x) = std::round(x)\nFor example, f(2.3) = 2, f(2.5) = 3, f(-2.5) = -3, f(-2.6) = -3.\n\n(2). If the round_mode = `DPU_ROUND`:\n\n    f(x) = ((x < 0) && (x - floor(x) == 0.5))\n           ? std::ceil(x)\n           : std::round(x)\nFor example, f(2.3) = 2, f(2.5) = 3, f(-2.5) = -2, f(-2.6) = -3.\n\n(3). If the round_mode = `PY3_ROUND`:\n\nRound to even.For example, f(2.3) = 2, f(2.5) = 2, f(-2.5) = -2, f(-2.6) = -3.\n\n"
  }
  attrs {
    name: "if_signed"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nIf the output feature maps is signed, this attr is set to be true."
  }
  annotation: "Transform the fixed value x into float output:\n\n(1). if_signed == true:\n\n    output = max(-pow(2, bit_width - 1),\n                 min(x, pow(2, bit_width - 1) - 1)))\n               * pow(2, -fix_point)\n(2). if_signed == false:\n\n    output = max(0, min(x, pow(2, bit_width) - 1)))\n               * pow(2, -fix_point)\n"
}
op_defs {
  name: "div"
  input_args {
    name: "input"
    occur_type: REQUIRED_AND_REPEATED
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "We support broadcasting operations:\n\n    \"add\": input[0] + input[1]\n    \"sub\": input[0] - input[1]\n    \"mul\": input[0] * input[1]\n    \"div\": input[0] / input[1]\n    \"min\": min(input[0], input[1])\n    \"max\": max(input[0], input[1])\nWhat is broadcasting?\n\nWhen operating on two arrays, we compare their shapes element-wise. \nIt starts with the trailing dimensions, and works its way forward.\n\nTwo dimensions are compatible when:\n\n1. they are equal, or\n2. one of them is 1\nIf these conditions are not met, a mismatch would be thrown, \nindicating that the arrays have incompatible shapes. \nThe size of the resulting array is the maximum size \nalong each dimension of the input arrays.\nFor example,\n\n(1). bias_add, which is a channel-wise operation:\n\n    input[0] (4d tensor): 1 x 112 x 112 x 64\n    input[1] (1d tensor):                 64\n    result   (4d tensor): 1 x 112 x 112 x 64\n(2). element-wise add, which is an element-wise operation:\n\n    input[0] (3d tensor): 32 x 32 x 10\n    input[1] (3d tensor): 32 x 32 x 10\n    result   (3d tensor): 32 x 32 x 10\n(3). more examples:\n\n    input[0] (4d tensor): 1 x 32 x 32 x 10\n    input[1] (3d tensor):     32 x  1 x  1\n    result   (4d tensor): 1 x 32 x 32 x 10\n(4). mismatched examples:\n\n    input[0] (4d tensor): 1 x 32 x 32 x 10\n    input[1] (3d tensor):      1 x 32 x  2\n    result              :         mismatch\n"
}
op_defs {
  name: "min"
  input_args {
    name: "input"
    occur_type: REQUIRED_AND_REPEATED
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "We support broadcasting operations:\n\n    \"add\": input[0] + input[1]\n    \"sub\": input[0] - input[1]\n    \"mul\": input[0] * input[1]\n    \"div\": input[0] / input[1]\n    \"min\": min(input[0], input[1])\n    \"max\": max(input[0], input[1])\nWhat is broadcasting?\n\nWhen operating on two arrays, we compare their shapes element-wise. \nIt starts with the trailing dimensions, and works its way forward.\n\nTwo dimensions are compatible when:\n\n1. they are equal, or\n2. one of them is 1\nIf these conditions are not met, a mismatch would be thrown, \nindicating that the arrays have incompatible shapes. \nThe size of the resulting array is the maximum size \nalong each dimension of the input arrays.\nFor example,\n\n(1). bias_add, which is a channel-wise operation:\n\n    input[0] (4d tensor): 1 x 112 x 112 x 64\n    input[1] (1d tensor):                 64\n    result   (4d tensor): 1 x 112 x 112 x 64\n(2). element-wise add, which is an element-wise operation:\n\n    input[0] (3d tensor): 32 x 32 x 10\n    input[1] (3d tensor): 32 x 32 x 10\n    result   (3d tensor): 32 x 32 x 10\n(3). more examples:\n\n    input[0] (4d tensor): 1 x 32 x 32 x 10\n    input[1] (3d tensor):     32 x  1 x  1\n    result   (4d tensor): 1 x 32 x 32 x 10\n(4). mismatched examples:\n\n    input[0] (4d tensor): 1 x 32 x 32 x 10\n    input[1] (3d tensor):      1 x 32 x  2\n    result              :         mismatch\n"
}
op_defs {
  name: "fix"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "fix_point"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nThe fixed position of the output feature maps."
  }
  attrs {
    name: "bit_width"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nThe bit width of the output feature maps."
  }
  attrs {
    name: "round_mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nThe round mode function for transforming the float data.The round mode is one of `{STD_ROUND, DPU_ROUND, PY3_ROUND}`\n\n(1). If the round_mode = `STD_ROUND`:\n\n    f(x) = std::round(x)\nFor example, f(2.3) = 2, f(2.5) = 3, f(-2.5) = -3, f(-2.6) = -3.\n\n(2). If the round_mode = `DPU_ROUND`:\n\n    f(x) = ((x < 0) && (x - floor(x) == 0.5))\n           ? std::ceil(x)\n           : std::round(x)\nFor example, f(2.3) = 2, f(2.5) = 3, f(-2.5) = -2, f(-2.6) = -3.\n\n(3). If the round_mode = `PY3_ROUND`:\n\nRound to even.For example, f(2.3) = 2, f(2.5) = 2, f(-2.5) = -2, f(-2.6) = -3.\n\n"
  }
  attrs {
    name: "if_signed"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nIf the output feature maps is signed, this attr is set to be true."
  }
  annotation: "fix operator transforms float-point value into fixed-point value into float-point format.\n\n(1). Firstly, we transform the float input feature map x into fixed value:\n\n    fixed_value = round(x * pow(2, fix_point))\nand then\n\n(2) transform the fixed value into float-point format:\n\n-> if_signed == true:\n\n    output = max(-pow(2, bit_width - 1),\n                 min(fixed_value, pow(2, bit_width - 1) - 1)))\n               * pow(2, -fix_point)\n-> if_signed == false:\n\n    output = max(0, min(fixed_value, pow(2, bit_width) - 1)))\n               * pow(2, -fix_point)\n"
}
op_defs {
  name: "float2fix"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "fix_point"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nThe fixed position of the output feature maps."
  }
  attrs {
    name: "bit_width"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nThe bit width of the output feature maps."
  }
  attrs {
    name: "round_mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nThe round mode function for transforming the float data.The round mode is one of `{STD_ROUND, DPU_ROUND, PY3_ROUND}`\n\n(1). If the round_mode = `STD_ROUND`:\n\n    f(x) = std::round(x)\nFor example, f(2.3) = 2, f(2.5) = 3, f(-2.5) = -3, f(-2.6) = -3.\n\n(2). If the round_mode = `DPU_ROUND`:\n\n    f(x) = ((x < 0) && (x - floor(x) == 0.5))\n           ? std::ceil(x)\n           : std::round(x)\nFor example, f(2.3) = 2, f(2.5) = 3, f(-2.5) = -2, f(-2.6) = -3.\n\n(3). If the round_mode = `PY3_ROUND`:\n\nRound to even.For example, f(2.3) = 2, f(2.5) = 2, f(-2.5) = -2, f(-2.6) = -3.\n\n"
  }
  attrs {
    name: "if_signed"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nIf the output feature maps is signed, this attr is set to be true."
  }
  annotation: "Transform the float value x into fixed value:\n\n    f(x) = round(x * pow(2, fix_point))\nThe round function is determined by the round_mode.\n\n(1). if_signed == true:\n\n    output = max(-pow(2, bit_width - 1),\n                 min(f(x), pow(2, bit_width - 1) - 1)))\n(2). if_signed == false:\n\n    output = max(0, min(f(x), pow(2, bit_width) - 1)))\n"
}
op_defs {
  name: "transposed-conv3d-fix"
  input_args {
    name: "input"
    data_type: 2
    annotation: "An input tensor with shape `[batch, in_height, in_width, in_depth, in_channels]`."
  }
  input_args {
    name: "weights"
    data_type: 2
    annotation: "A filter tensor with shape `[output_channels, kernel_height, kernel_width, kernel_depth, in_channels]`."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 2
    annotation: "A bias tensor with shape `[output_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height}`."
  }
  attrs {
    name: "dilation"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 1
        value: 1
        value: 1
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 6
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.\n\nFor transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don\'t need to specify this attribute."
  }
  attrs {
    name: "nonlinear"
    occur_type: OPTIONAL
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nnonlinear type, \"NONE\", \"RELU\", \"PRELU\", \"LEAKYRELU\",\"RELU6\",\"HSIGMOID\",\"HSWISH\"."
  }
}
op_defs {
  name: "conv2d"
  input_args {
    name: "input"
    data_type: 4
    annotation: "An input tensor with shape `[batch, in_height, in_width, in_channels]`."
  }
  input_args {
    name: "weights"
    data_type: 4
    annotation: "A filter tensor with shape `[output_channels, kernel_height, kernel_width, in_channels]`."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 4
    annotation: "A bias tensor with shape `[output_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height}`."
  }
  attrs {
    name: "dilation"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 1
        value: 1
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default."
  }
  attrs {
    name: "pad_mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nWe support 4 padding mode: `FLOOR, CEIL, SAME, VALID`. For example, when you parsing models from other frameworks, `caffe, pytorch->\"FLOOR\", tensorflow->\"SAME\" or \"VALID\"`."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 4
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.\n\nFor transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don\'t need to specify this attribute."
  }
  annotation: "2D convolution.\n\n    output[batch, oh, ow, oc] =\n        sum_{kw, kh, ic} input[batch, strides[1] * oh + kh, strides[0] * ow + kw, ic] *\n                        filter[oc, kh, kw, ic]\n(1). if pad_mode == \"`FLOOR`\":\n\n    output_shape = floor((input_shape + pad - (kernel - 1) * dilation + 1) / stride) + 1\n(2). if pad_mode == \"`CEIL`\":\n\n    output_shape = ceil((input_shape + pad - (kernel - 1) * dilation + 1) / stride) + 1\n(3). if pad_mode == \"`SAME`\":\n\n    output_shape = ceil((input_shape + pad) / stride)\n(4). if pad_mode == \"`VALID`\":\n\n    output_shape = ceil((input_shape + pad - (kernel - 1) * dilation) / stride)\n"
}
op_defs {
  name: "depthwise-conv2d"
  input_args {
    name: "input"
    data_type: 4
    annotation: "An input tensor with shape `[batch, in_height, in_width, in_channels]`."
  }
  input_args {
    name: "weights"
    data_type: 4
    annotation: "A filter tensor with shape `[output_channels, kernel_height, kernel_width, in_channels]`."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 4
    annotation: "A bias tensor with shape `[output_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height}`."
  }
  attrs {
    name: "dilation"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 1
        value: 1
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default."
  }
  attrs {
    name: "pad_mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nWe support 4 padding mode: `FLOOR, CEIL, SAME, VALID`. For example, when you parsing models from other frameworks, `caffe, pytorch->\"FLOOR\", tensorflow->\"SAME\" or \"VALID\"`."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 4
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.\n\nFor transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don\'t need to specify this attribute."
  }
  annotation: "Depth-wise 2D convolution.\n\n    output[batch, oh, ow, b * c] =\n        sum_{kw, kh} input[batch, strides[1] * oh + kh, strides[0] * ow + kw, c] *\n                        filter[b, kh, kw, c]\n(1). if pad_mode == \"`FLOOR`\":\n\n    output_shape = floor((input_shape + pad - (kernel - 1) * dilation + 1) / stride) + 1\n(2). if pad_mode == \"`CEIL`\":\n\n    output_shape = ceil((input_shape + pad - (kernel - 1) * dilation + 1) / stride) + 1\n(3). if pad_mode == \"`SAME`\":\n\n    output_shape = ceil((input_shape + pad) / stride)\n(4). if pad_mode == \"`VALID`\":\n\n    output_shape = ceil((input_shape + pad - (kernel - 1) * dilation) / stride)\nFor example, in Tensorflow, tf.nn.depthwise_conv2d is:\n\n    output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}\n        filter[di, dj, k, q] * input[b, stride[1] * i + rate[0] * di,\n                                        stride[2] * j + rate[1] * dk, k]\nGiven a 4D input tensor (\'NHWC\' or \'NCHW\' data formats) and a filter tensor of shape [filter_height, filter_width, in_channels, channel_multiplier]if we want to transform tf.nn.depthwise_conv2d into XIR depthwise-conv2d, then in XIR\n\n    output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}\n        filter[q, di, dj, k] * input[b, stride[1] * i + rate[0] * di,\n                                        stride[0] * j + rate[1] * dk, k]\nIn another example, for convolution in caffe, if the attribute `group` euqals to the input channels of the input feature maps, then this convolutioncan be transformed into a XIR depthwise-conv2d."
}
op_defs {
  name: "depthwise-conv2d-fix"
  input_args {
    name: "input"
    data_type: 2
    annotation: "An input tensor with shape `[batch, in_height, in_width, in_channels]`."
  }
  input_args {
    name: "weights"
    data_type: 2
    annotation: "A filter tensor with shape `[output_channels, kernel_height, kernel_width, in_channels]`."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 2
    annotation: "A bias tensor with shape `[output_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height}`."
  }
  attrs {
    name: "dilation"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 1
        value: 1
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 4
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.\n\nFor transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`."
  }
  attrs {
    name: "nonlinear"
    occur_type: OPTIONAL
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nnonlinear type, \"NONE\", \"RELU\", \"PRELU\", \"LEAKYRELU\",\"RELU6\",\"HSIGMOID\",\"HSWISH\"."
  }
}
op_defs {
  name: "add"
  input_args {
    name: "input"
    occur_type: REQUIRED_AND_REPEATED
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "We support broadcasting operations:\n\n    \"add\": input[0] + input[1]\n    \"sub\": input[0] - input[1]\n    \"mul\": input[0] * input[1]\n    \"div\": input[0] / input[1]\n    \"min\": min(input[0], input[1])\n    \"max\": max(input[0], input[1])\nWhat is broadcasting?\n\nWhen operating on two arrays, we compare their shapes element-wise. \nIt starts with the trailing dimensions, and works its way forward.\n\nTwo dimensions are compatible when:\n\n1. they are equal, or\n2. one of them is 1\nIf these conditions are not met, a mismatch would be thrown, \nindicating that the arrays have incompatible shapes. \nThe size of the resulting array is the maximum size \nalong each dimension of the input arrays.\nFor example,\n\n(1). bias_add, which is a channel-wise operation:\n\n    input[0] (4d tensor): 1 x 112 x 112 x 64\n    input[1] (1d tensor):                 64\n    result   (4d tensor): 1 x 112 x 112 x 64\n(2). element-wise add, which is an element-wise operation:\n\n    input[0] (3d tensor): 32 x 32 x 10\n    input[1] (3d tensor): 32 x 32 x 10\n    result   (3d tensor): 32 x 32 x 10\n(3). more examples:\n\n    input[0] (4d tensor): 1 x 32 x 32 x 10\n    input[1] (3d tensor):     32 x  1 x  1\n    result   (4d tensor): 1 x 32 x 32 x 10\n(4). mismatched examples:\n\n    input[0] (4d tensor): 1 x 32 x 32 x 10\n    input[1] (3d tensor):      1 x 32 x  2\n    result              :         mismatch\n"
}
op_defs {
  name: "maxpool2d"
  input_args {
    name: "input"
    data_type: 4
    annotation: "An input tensor with shape `[batch, in_height, in_width, in_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height}`."
  }
  attrs {
    name: "pad_mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nWe support 4 padding mode: FLOOR, CEIL, SAME, VALID. For example, when you parsing models from other frameworks, `caffe->\"CEIL\",  tensorflow->\"SAME\" or \"VALID\", pytorch->\"FLOOR\"(default) or \"CEIL\".`"
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 4
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom}`."
  }
  attrs {
    name: "global"
    occur_type: OPTIONAL
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nGlobal pooling, if global is set to be true, the width and height of output feature maps would be {1, 1}."
  }
  annotation: "2D max-pooling.\n\n    output[batch, oh, ow, c] =\n        max_{kw, kh} input[batch, strides[1] * oh + kh,\n           strides[0] * ow + kw, c] *\n(1). if pad_mode == \"`FLOOR`\":\n\n    output_shape = floor((input_shape + pad - kernel) / stride) + 1\n(2). if pad_mode == \"`CEIL`\":\n\n    output_shape = ceil((input_shape + pad - kernel) / stride) + 1\n(3). if pad_mode == \"`SAME`\":\n\n    output_shape = ceil((input_shape + pad) / stride)\n(4). if pad_mode == \"`VALID`\":\n\n    output_shape = ceil((input_shape + pad - kernel) / stride)\n"
}
op_defs {
  name: "transposed-conv2d"
  input_args {
    name: "input"
    data_type: 4
    annotation: "An input tensor with shape `[batch, in_height, in_width, in_channels]`."
  }
  input_args {
    name: "weights"
    data_type: 4
    annotation: "A filter tensor with shape `[output_channels, kernel_height, kernel_width, in_channels]`."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 4
    annotation: "A bias tensor with shape `[output_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height}`."
  }
  attrs {
    name: "dilation"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 1
        value: 1
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default."
  }
  attrs {
    name: "pad_mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nWe support 4 padding mode: `FLOOR, CEIL, SAME, VALID`. For example, when you parsing models from other frameworks, `caffe, pytorch->\"FLOOR\", tensorflow->\"SAME\" or \"VALID\"`."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 4
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.\n\nFor transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don\'t need to specify this attribute."
  }
  annotation: "2D transposed convolution, our equivalent implementations:\nFirstly, we dilate the input feature maps by `stride`:\n\n    dilated_input[batch, h, w, c] =\n        ((h mod stride[1] == 0) && (w mod stride[0] == 0))\n        ? input[batch, h / stride[1], h / stride[0], ic]\n        : 0\nSecondly, we do 2D-convolution on the feature maps:\n\n    output[batch, oh, ow, oc] =\n        sum_{kw, kh, ic} dilated_input[batch, oh + kh, ow + kw, ic] *\n                        filter[oc, kh, kw, ic]\nIf pad is set:\n\n    actual_padding[n] = kernel (h or w) - 1 - pad[n]\n    padded_dilated_input[batch, h - actual_padding[2], w - actual_padding[0], c] =\n        dilated_input[batch, h, w, c]\n    padded_dilated_input[batch, 0 : actual_padding[2], 0 : actual_padding[0], c] = 0\n    padded_dilated_input[batch, h + actual_padding[2] : h + actual_padding[2] + actual_padding[3]\n                         w + actual_padding[0] : w + actual_padding[0] + actual_padding[1], c] = 0\nAnd here is how to calculate the output shape according to the attributes:\n\n(1). if pad_mode == \"`FLOOR`\":\n\n    output_shape = (in_shape - 1) * stride + dilation * (kernel - 1) + 1 - pad\n(2). if pad_mode == \"`CEIL`\":\n\n    output_shape = (in_shape - 1) * stride + dilation * (kernel - 1) + 1 - pad\n(3). if pad_mode == \"`SAME`\":\n\n    output_shape = in_shape * stride\n(4). if pad_mode == \"`VALID`\":\n\n    output_shape = (in_shape - 1) * stride + kernel\nFor example, to transform a conv2d_transpose or Conv2DBackpropInput in Tensorflow into XIR:\nwe only need to change the filter in tensorflow into XIR format.\n\n(1). flip the filter along the dimension of width and height,\n\n(2). transpose the filter into `{oc, h, w, ic}`, ic equals the channel of input feature maps and oc equals to the channel of output feature maps."
}
op_defs {
  name: "elu"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "alpha"
    occur_type: OPTIONAL
    default_value {
      float_value: 1
    }
    list_length: 1
    annotation: "`Datatype`: `float`\n\nSlope of the activation function at x <= 0."
  }
  annotation: "Computes the elu function element-wise:\n\n    f(x) = x if x > 0.\n    f(x) = alpha * (exp(x) - 1) if x <= 0.\n"
}
op_defs {
  name: "sub"
  input_args {
    name: "input"
    occur_type: REQUIRED_AND_REPEATED
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "We support broadcasting operations:\n\n    \"add\": input[0] + input[1]\n    \"sub\": input[0] - input[1]\n    \"mul\": input[0] * input[1]\n    \"div\": input[0] / input[1]\n    \"min\": min(input[0], input[1])\n    \"max\": max(input[0], input[1])\nWhat is broadcasting?\n\nWhen operating on two arrays, we compare their shapes element-wise. \nIt starts with the trailing dimensions, and works its way forward.\n\nTwo dimensions are compatible when:\n\n1. they are equal, or\n2. one of them is 1\nIf these conditions are not met, a mismatch would be thrown, \nindicating that the arrays have incompatible shapes. \nThe size of the resulting array is the maximum size \nalong each dimension of the input arrays.\nFor example,\n\n(1). bias_add, which is a channel-wise operation:\n\n    input[0] (4d tensor): 1 x 112 x 112 x 64\n    input[1] (1d tensor):                 64\n    result   (4d tensor): 1 x 112 x 112 x 64\n(2). element-wise add, which is an element-wise operation:\n\n    input[0] (3d tensor): 32 x 32 x 10\n    input[1] (3d tensor): 32 x 32 x 10\n    result   (3d tensor): 32 x 32 x 10\n(3). more examples:\n\n    input[0] (4d tensor): 1 x 32 x 32 x 10\n    input[1] (3d tensor):     32 x  1 x  1\n    result   (4d tensor): 1 x 32 x 32 x 10\n(4). mismatched examples:\n\n    input[0] (4d tensor): 1 x 32 x 32 x 10\n    input[1] (3d tensor):      1 x 32 x  2\n    result              :         mismatch\n"
}
op_defs {
  name: "conv3d"
  input_args {
    name: "input"
    data_type: 4
    annotation: "An input tensor with shape `[batch, in_height, in_width, depth, in_channels]`."
  }
  input_args {
    name: "weights"
    data_type: 4
    annotation: "A filter tensor with shape `[output_channels, kernel_height, kernel_width, kernel_depth, in_channels]`."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 4
    annotation: "A bias tensor with shape `[output_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height, kernel_depth}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height, stride_depth}`."
  }
  attrs {
    name: "dilation"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 1
        value: 1
        value: 1
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe dilation of the filter. The value must be: `{dilation_width, dilation_height, dilation_depth}`, The dilation in the batch or depth are 1 in default."
  }
  attrs {
    name: "pad_mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nWe support 4 padding mode: `FLOOR, CEIL, SAME, VALID`. For example, when you parsing models from other frameworks, `caffe, pytorch->\"FLOOR\", tensorflow->\"SAME\" or \"VALID\"`."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 6
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom, near, far}`.\n\nFor transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don\'t need to specify this attribute."
  }
  annotation: "3D convolution.\n\n"
}
op_defs {
  name: "depthwise-conv3d"
  input_args {
    name: "input"
    data_type: 4
    annotation: "An input tensor with shape `[batch, in_height, in_width, depth, in_channels]`."
  }
  input_args {
    name: "weights"
    data_type: 4
    annotation: "A filter tensor with shape `[output_channels, kernel_height, kernel_width, kernel_depth, in_channels]`."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 4
    annotation: "A bias tensor with shape `[output_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height, kernel_depth}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height, stride_depth}`."
  }
  attrs {
    name: "dilation"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 1
        value: 1
        value: 1
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe dilation of the filter. The value must be: `{dilation_width, dilation_height, dilation_depth}`, The dilation in the batch or depth are 1 in default."
  }
  attrs {
    name: "pad_mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nWe support 4 padding mode: `FLOOR, CEIL, SAME, VALID`. For example, when you parsing models from other frameworks, `caffe, pytorch->\"FLOOR\", tensorflow->\"SAME\" or \"VALID\"`."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 6
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom, near, far}`.\n\nFor transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don\'t need to specify this attribute."
  }
  annotation: "Depth-wise 3D convolution.\n\n"
}
op_defs {
  name: "celu"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "alpha"
    occur_type: OPTIONAL
    default_value {
      float_value: 1
    }
    list_length: 1
    annotation: "`Datatype`: `float`\n\nSlope of the activation function."
  }
  annotation: "Computes the celu function element-wise:\n\n    f(x) = max(0, x) + min(0, alpha * (exp(x / alpha) - 1)).\n"
}
op_defs {
  name: "shape"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "Return the shape of the input feature maps."
}
op_defs {
  name: "pool-fix"
  input_args {
    name: "input"
    data_type: 2
    annotation: "An input tensor with shape `[batch, in_height, in_width, in_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 2
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height}`."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 4
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom}`. This is an optional attribute, when the pad_mode is SAME or VALID, you don\'t need to specify this attribute."
  }
  attrs {
    name: "type"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nDpu pooling type, \"MAX\", \"AVG\"."
  }
}
op_defs {
  name: "transposed-conv3d"
  input_args {
    name: "input"
    data_type: 4
    annotation: "An input tensor with shape `[batch, in_height, in_width, depth, in_channels]`."
  }
  input_args {
    name: "weights"
    data_type: 4
    annotation: "A filter tensor with shape `[output_channels, kernel_height, kernel_width, kernel_depth, in_channels]`."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 4
    annotation: "A bias tensor with shape `[output_channels]`."
  }
  attrs {
    name: "kernel"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe kernel sizes of the filter. The value must be: `{kernel_width, kernel_height, kernel_depth}`."
  }
  attrs {
    name: "stride"
    default_value {
      int32_vec_value {
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe strides of the filter. The value must be: `{stride_width, stride_height, stride_depth}`."
  }
  attrs {
    name: "dilation"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 1
        value: 1
        value: 1
      }
    }
    list_length: 3
    annotation: "`Datatype`: `vector<int>`\n\nThe dilation of the filter. The value must be: `{dilation_width, dilation_height, dilation_depth}`, The dilation in the batch or depth are 1 in default."
  }
  attrs {
    name: "pad_mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nWe support 4 padding mode: `FLOOR, CEIL, SAME, VALID`. For example, when you parsing models from other frameworks, `caffe, pytorch->\"FLOOR\", tensorflow->\"SAME\" or \"VALID\"`."
  }
  attrs {
    name: "pad"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
        value: 0
        value: 0
        value: 0
        value: 0
        value: 0
      }
    }
    list_length: 6
    annotation: "`Datatype`: `vector<int>`\n\nThe padding sizes of input feature maps. The value must be `{left, right, top, bottom, near, far}`.\n\nFor transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don\'t need to specify this attribute."
  }
  annotation: "Transposed 3D convolution.\n\n"
}
op_defs {
  name: "gelu"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "Computes the gelu function element-wise:\n\n    f(x) = x * 1 / 2 * (1 + erf(x / sqrt(2))).\n"
}
op_defs {
  name: "max"
  input_args {
    name: "input"
    occur_type: REQUIRED_AND_REPEATED
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "We support broadcasting operations:\n\n    \"add\": input[0] + input[1]\n    \"sub\": input[0] - input[1]\n    \"mul\": input[0] * input[1]\n    \"div\": input[0] / input[1]\n    \"min\": min(input[0], input[1])\n    \"max\": max(input[0], input[1])\nWhat is broadcasting?\n\nWhen operating on two arrays, we compare their shapes element-wise. \nIt starts with the trailing dimensions, and works its way forward.\n\nTwo dimensions are compatible when:\n\n1. they are equal, or\n2. one of them is 1\nIf these conditions are not met, a mismatch would be thrown, \nindicating that the arrays have incompatible shapes. \nThe size of the resulting array is the maximum size \nalong each dimension of the input arrays.\nFor example,\n\n(1). bias_add, which is a channel-wise operation:\n\n    input[0] (4d tensor): 1 x 112 x 112 x 64\n    input[1] (1d tensor):                 64\n    result   (4d tensor): 1 x 112 x 112 x 64\n(2). element-wise add, which is an element-wise operation:\n\n    input[0] (3d tensor): 32 x 32 x 10\n    input[1] (3d tensor): 32 x 32 x 10\n    result   (3d tensor): 32 x 32 x 10\n(3). more examples:\n\n    input[0] (4d tensor): 1 x 32 x 32 x 10\n    input[1] (3d tensor):     32 x  1 x  1\n    result   (4d tensor): 1 x 32 x 32 x 10\n(4). mismatched examples:\n\n    input[0] (4d tensor): 1 x 32 x 32 x 10\n    input[1] (3d tensor):      1 x 32 x  2\n    result              :         mismatch\n"
}
op_defs {
  name: "relu6"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "Computes the relu6 function element-wise:\n\n    f(x) = min(max(x, 0), 6).\n"
}
op_defs {
  name: "neg"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "This function computes the numerical negative value element-wise.\n\n    f(x) = -x\n"
}
op_defs {
  name: "depthwise-fix"
  input_args {
    name: "input"
    occur_type: REQUIRED_AND_REPEATED
    data_type: 2
    annotation: "The feature maps, can be x-dimension. depthwise-fix operator implements channel-wise operations."
  }
  attrs {
    name: "type"
    occur_type: OPTIONAL
    default_value {
      string_value: "MUL"
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\ndepthwise type, \"ADD\", \"MUL\". Default is \"ADD\""
  }
}
op_defs {
  name: "priorbox"
  input_args {
    name: "input"
    occur_type: REQUIRED_AND_REPEATED
    data_type: 4
    annotation: "`[batch, in_height, in_width, in_channels]`."
  }
  attrs {
    name: "min_sizes"
    default_value {
      float_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<float>`\n\nminimum box size (in pixels)"
  }
  attrs {
    name: "max_sizes"
    occur_type: OPTIONAL
    default_value {
      float_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<float>`\n\nmaximum box size (in pixels)"
  }
  attrs {
    name: "aspect_ratio"
    occur_type: OPTIONAL
    default_value {
      float_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<float>`\n\nvarious of aspect ratios"
  }
  attrs {
    name: "flip"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nif true, will flip each aspect ratio, default True"
  }
  attrs {
    name: "clip"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nif true, will clip the prior so that it is within [0, 1]."
  }
  attrs {
    name: "variance"
    default_value {
      float_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<float>`\n\nvariance for adjusting the prior bboxes"
  }
  attrs {
    name: "step"
    default_value {
      float_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<float>`\n\nstep size"
  }
  attrs {
    name: "offset"
    default_value {
      float_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `vector<float>`\n\noffset to the top left corner of each cell."
  }
}
op_defs {
  name: "inner-product"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  input_args {
    name: "weights"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  input_args {
    name: "bias"
    occur_type: OPTIONAL
    data_type: 4
    annotation: "1-dimension, OC"
  }
  attrs {
    name: "axis"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\n[axis:-1] for flatten"
  }
  annotation: "Do inner-product for the input feature maps.\n\nFor example, the shape of the input is [n, a, b, c], axis = 1, Firstly, flatten the input feature maps starting from the `axis` dimension to the end. the input would be reshaped to [n, a * b * c].\n\nSecondly, the weights would be reshaped to [k, a * b * c], \n\nThirdly, the inner-product would be implemented:\n\n    output[n, k] = sum_{i} input(n, i) * weights(k, i)\nThe number of bias equals to k."
}
op_defs {
  name: "sigmoid"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "Computes the sigmoid function element-wise:\n\n    f(x) = 1 / (1 + exp(-x)).\n"
}
op_defs {
  name: "pad"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "paddings"
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\npad along different dimensions, the number of value in paddings should be 2 times the number of dimensions of input feature maps.The n-th dimension of the output feature maps equals to:\n\n    (n-th dim) out =\n        paddings[2n] + (n-th dim) in + paddings[2n + 1]"
  }
  attrs {
    name: "mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\n`CONSTANT`,`REFLECT` or `SYMMETRIC`"
  }
  attrs {
    name: "constant_values"
    occur_type: OPTIONAL
    default_value {
      float_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<float>`\n\nthe value set into the padded locations, 2 * len(paddings)"
  }
  annotation: "For example,\n\nif the mode = \"CONSTANT\"\n\n    input = [[1, 2],\n             [3, 4]]\n    paddings = [0, 1, 1, 0]\n    output = [[0, 1, 2],\n              [0, 3, 4],\n              [0, 0, 0]]\nif the mode = \"REFLECT\"\n\n    input = [[1, 2],\n             [3, 4]]\n    paddings = [0, 1, 1, 0]\n    output = [[2, 1, 2],\n              [4, 3, 4],\n              [2, 1, 2]]\nif the mode = \"SYMMETRIC\"\n\n    input = [[1, 2],\n             [3, 4]]\n    paddings = [0, 1, 1, 0]\n    output = [[1, 1, 2],\n              [3, 3, 4],\n              [3, 3, 4]]\n"
}
op_defs {
  name: "upsample-fix"
  input_args {
    name: "input"
    data_type: 2
    annotation: "The feature maps, can be x-dimension."
  }
  input_args {
    name: "size"
    occur_type: OPTIONAL
    annotation: "Constant values denotes the shape of the output feature maps."
  }
  attrs {
    name: "mode"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nNEAREST, BILINEAR or TRILINEAR"
  }
  attrs {
    name: "align_corners"
    occur_type: OPTIONAL
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nIf true, preserving the values at the corner pixels. Defaults to false."
  }
  attrs {
    name: "half_pixel_centers"
    occur_type: OPTIONAL
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nIf true, use half-pixel as centers."
  }
  attrs {
    name: "scale"
    default_value {
      float_vec_value {
      }
    }
    list_length: 2
    annotation: "`DataType` : `std::vector<float>` {scale_w, scale_h}"
  }
}
op_defs {
  name: "swish"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "Computes the swish function element-wise:\n\n    f(x) = x * sigmoid(x).\n"
}
op_defs {
  name: "identity"
  input_args {
    name: "input"
    data_type: 2
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "An interface operator that holds the data. Do nothing here."
}
op_defs {
  name: "tanh"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "Computes the tanh function element-wise:\n\n    f(x) = tanh(x).\n"
}
op_defs {
  name: "hard-sigmoid-fix"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "Computes the hard sigmoid function element-wise:\n\n    f(x) = relu6(x + 3) * 2731 / 2 ^ 14.\n"
}
op_defs {
  name: "hard-tanh"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "Computes the hard tanh function element-wise:\n\n    f(x) = clip(x, -1, 1).\n"
}
op_defs {
  name: "threshold"
  input_args {
    name: "input"
    data_type: 2
    annotation: "The feature maps, can be x-dimension."
  }
  input_args {
    name: "threshold"
    data_type: 2
    annotation: "1-dimension, 24-bit XINT"
  }
  annotation: "Threshold operator is used to transform fixed-point values \nto fixed-point values of different bit width.\n\n    24 bit threshold = 13-bit base + 10-bit delta + 1-bit signal.\nbase is a channel-wise parameter, an int_13 number.\n11 bit interger and 2 bit decimal.\n\ndelta is a channel-wise parameter, an uint_10 number.\n8 bit interger and 2 bit decimal.\n\nThe output can be calculated by this function:\n\n    base + out * delta <= in < base + (out + 1) * delta\nIn addition, signal indicates whether actual step is a positive number.\n0 indicates positive, 1 is negative.\n"
}
op_defs {
  name: "reduction_mean"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "axis"
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nThe dimensions to reduce."
  }
  attrs {
    name: "keep_dims"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nspecify whether the reduced dimension is kept or not."
  }
  annotation: "Implement the mean along each of the axis dimensions."
}
op_defs {
  name: "gstiling"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "reverse"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nif reverse"
  }
  attrs {
    name: "stride"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nstride for feature maps"
  }
}
op_defs {
  name: "mul"
  input_args {
    name: "input"
    occur_type: REQUIRED_AND_REPEATED
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "We support broadcasting operations:\n\n    \"add\": input[0] + input[1]\n    \"sub\": input[0] - input[1]\n    \"mul\": input[0] * input[1]\n    \"div\": input[0] / input[1]\n    \"min\": min(input[0], input[1])\n    \"max\": max(input[0], input[1])\nWhat is broadcasting?\n\nWhen operating on two arrays, we compare their shapes element-wise. \nIt starts with the trailing dimensions, and works its way forward.\n\nTwo dimensions are compatible when:\n\n1. they are equal, or\n2. one of them is 1\nIf these conditions are not met, a mismatch would be thrown, \nindicating that the arrays have incompatible shapes. \nThe size of the resulting array is the maximum size \nalong each dimension of the input arrays.\nFor example,\n\n(1). bias_add, which is a channel-wise operation:\n\n    input[0] (4d tensor): 1 x 112 x 112 x 64\n    input[1] (1d tensor):                 64\n    result   (4d tensor): 1 x 112 x 112 x 64\n(2). element-wise add, which is an element-wise operation:\n\n    input[0] (3d tensor): 32 x 32 x 10\n    input[1] (3d tensor): 32 x 32 x 10\n    result   (3d tensor): 32 x 32 x 10\n(3). more examples:\n\n    input[0] (4d tensor): 1 x 32 x 32 x 10\n    input[1] (3d tensor):     32 x  1 x  1\n    result   (4d tensor): 1 x 32 x 32 x 10\n(4). mismatched examples:\n\n    input[0] (4d tensor): 1 x 32 x 32 x 10\n    input[1] (3d tensor):      1 x 32 x  2\n    result              :         mismatch\n"
}
op_defs {
  name: "hard-swish"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "Computes the hard swish function element-wise:\n\n    f(x) = x * relu6(x + 3) / 6.\n"
}
op_defs {
  name: "reduction_sum"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "axis"
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nThe dimensions to reduce."
  }
  attrs {
    name: "keep_dims"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nspecify whether the reduced dimension is kept or not."
  }
  annotation: "Implement the sum along each of the axis dimensions."
}
op_defs {
  name: "leaky-relu"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "alpha"
    default_value {
      float_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `float`\n\nSlope of the activation function at x < 0."
  }
  annotation: "Computes the leaky relu function element-wise:\n\n    f(x) = min(x, 0) + alpha * min(x, 0).\n"
}
op_defs {
  name: "reduction_max"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "axis"
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nThe dimensions to reduce."
  }
  attrs {
    name: "keep_dims"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nspecify whether the reduced dimension is kept or not."
  }
  annotation: "Find the maximum value along each of the axis dimensions."
}
op_defs {
  name: "pixel-shuffle"
  input_args {
    name: "input"
    data_type: 4
    annotation: "`[batch, in_height, in_width, in_channels]`."
  }
  attrs {
    name: "scale"
    default_value {
      int32_value: 0
    }
    list_length: 1
    annotation: "`Datatype`: `int`\n\nscale for PixelShuffle"
  }
  attrs {
    name: "upscale"
    default_value {
      bool_value: false
    }
    list_length: 1
    annotation: "`Datatype`: `bool`\n\nupscale or downscale PixelShuffle."
  }
  annotation: "https://pytorch.org/docs/stable/generated/torch.nn.PixelShuffle.html"
}
op_defs {
  name: "l2_normalize"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  attrs {
    name: "axis"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nDimension along which to normalize."
  }
  attrs {
    name: "epsilon"
    occur_type: OPTIONAL
    default_value {
      double_value: 1e-12
    }
    list_length: 1
    annotation: "`Datatype`: `double`\n\nA lower bound value for the norm."
  }
  annotation: "For a 1-D tensor with `axis = 0`, computes\n\n    output = x / sqrt(max(sum(x ^ 2), epsilon))\nFor x with more dimensions,\nindependently normalizes each 1-D slice along dimension axis.\n"
}
op_defs {
  name: "data"
  attrs {
    name: "shape"
    default_value {
      int32_vec_value {
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nThe shape of the output tensor"
  }
  attrs {
    name: "data_type"
    default_value {
      string_value: ""
    }
    list_length: 1
    annotation: "`Datatype`: `string`\n\nThe data type of the data of output feature maps, we use FLOAT32 as the default."
  }
  annotation: "A placeholder which stores the float-point input data, \ndata operator would always be fed by users."
}
op_defs {
  name: "placeholder"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "An interface operator that holds the data. Do nothing here."
}
op_defs {
  name: "selu"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  annotation: "Computes the selu function element-wise:\n\n    f(x) = scale * (max(0, x) + min(0, alpha * (exp(x) - 1))).\nalpha and scale are constant value.\n"
}
op_defs {
  name: "reshape"
  input_args {
    name: "input"
    data_type: 4
    annotation: "The feature maps, can be x-dimension."
  }
  input_args {
    name: "shape"
    occur_type: OPTIONAL
    annotation: "Constant values that define the shape of the output."
  }
  attrs {
    name: "shape"
    occur_type: OPTIONAL
    default_value {
      int32_vec_value {
        value: 0
      }
    }
    annotation: "`Datatype`: `vector<int>`\n\nConstant values that define the shape of the output."
  }
  annotation: "Reshape the feature maps or constant data into new shape without changing the layout of data in memory."
}
